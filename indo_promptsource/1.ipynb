{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ihza.mahendra/anaconda3/envs/promptsource/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-08-18 08:43:49 [INFO]: Input dataset_name: indolem_ntp\n",
      "2023-08-18 08:43:49 [INFO]: Input subset_name: nusa\n",
      "2023-08-18 08:43:49 [DEBUG]: open file: /Users/ihza.mahendra/.cache/huggingface/datasets/indolem_ntp/indolem_ntp_nusantara_pairs/1.0.0/8d9cc999349598c3aa62da2c4e2d3aab4c7a96cc98441739883113e6a124f9df/dataset_info.json\n",
      "2023-08-18 08:43:49 [DEBUG]: open file: /Users/ihza.mahendra/.cache/huggingface/datasets/indolem_ntp/indolem_ntp_nusantara_pairs/1.0.0/8d9cc999349598c3aa62da2c4e2d3aab4c7a96cc98441739883113e6a124f9df/dataset_info.json\n",
      "2023-08-18 08:43:49 [INFO]: ============================================\n",
      "2023-08-18 08:43:49 [INFO]: ## DATASET INFO ##\n",
      "2023-08-18 08:43:49 [INFO]: Real dataset_name: indolem_ntp\n",
      "2023-08-18 08:43:49 [INFO]: Real subset_name: indolem_ntp_nusantara_pairs\n",
      "2023-08-18 08:43:49 [INFO]: dset.shape: {'train': (22724, 4), 'test': (7560, 4), 'validation': (3244, 4)}\n",
      "2023-08-18 08:43:49 [INFO]: Example dataset: {'id': '0', 'text_1': '+ Deposito: Investasi sangat likuid, return tetap dan stabil, jauh dari risiko gagal bayar kalau diletakkan di bank yang dijamin LPS dengan catatan &lt; Rp 2 Miliar. Kesimpulannya, keunggulan deposito adalah safety factor alias keamanan dan low risk. - Deposito: Banyak investasi yang lebih menjamin return yang lebih menjanjikan.Suku bunga sudah mulai kecil, dibandingkan dengan zaman dahulu.Masih dipotong pajak dan tergerus inflasi.', 'text_2': 'RT  Sejatinya teman2 buruh tdk perlu demo karena darurat Corona. Akan ttpi mata, telinga dan hati para anggota DPR RI sudah tert…', 'label': 0}\n",
      "2023-08-18 08:43:49 [INFO]: ============================================\n",
      "100%|██████████| 10/10 [04:31<00:00, 27.16s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from promptsource.templates import DatasetTemplates\n",
    "# !pip install nusacrowd\n",
    "from nusacrowd import NusantaraConfigHelper\n",
    "import logging\n",
    "import argparse\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--dataset-name', help='Dataset name')\n",
    "# parser.add_argument('--subset-name', help='Subset name')\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# Set up the logger\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,  # Set the desired logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)\n",
    "    format='%(asctime)s [%(levelname)s]: %(message)s',  # Customize the log message format\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'  # Customize the date/time format\n",
    ")\n",
    "\n",
    "# Create a file handler to write logs into a file\n",
    "file_handler = logging.FileHandler('app.log')\n",
    "file_handler.setLevel(logging.DEBUG)  # Set the log level for the file handler\n",
    "\n",
    "# Create a formatter for the file handler (customize the log format for the file)\n",
    "file_formatter = logging.Formatter('%(asctime)s [%(levelname)s]: %(message)s', datefmt='%Y-%m-%d %H:%M:%S')\n",
    "file_handler.setFormatter(file_formatter)\n",
    "\n",
    "logger = logging.getLogger(\"IndoP3 Dataset Generation\")\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "conhelps = NusantaraConfigHelper()\n",
    "\n",
    "all_data = []\n",
    "checkpoint_save_path = \"generated_dataset\"\n",
    "\n",
    "dataset_name = \"indolem_ntp\" #args.dataset_name\n",
    "subset_name = \"nusa\" #args.subset_name\n",
    "logger.info(f\"Input dataset_name: {dataset_name}\")\n",
    "logger.info(f\"Input subset_name: {subset_name}\")\n",
    "\n",
    "# Load dataset\n",
    "nusa_metadata = conhelps.filtered(lambda x: dataset_name in x.dataset_name and subset_name in x.config.name)[0]\n",
    "dataset_name = nusa_metadata.dataset_name\n",
    "subset_name = nusa_metadata.config.name\n",
    "dset = nusa_metadata.load_dataset()\n",
    "logger.info(\"============================================\")\n",
    "logger.info(f\"## DATASET INFO ##\")\n",
    "logger.info(f\"Real dataset_name: {dataset_name}\")\n",
    "logger.info(f\"Real subset_name: {subset_name}\")\n",
    "logger.info(f\"dset.shape: {dset.shape}\")\n",
    "example = dset[\"train\"][0]\n",
    "logger.info(f\"Example dataset: {example}\")\n",
    "logger.info(\"============================================\")\n",
    "\n",
    "\n",
    "# Load prompt\n",
    "prompt = DatasetTemplates(dataset_name, subset_name=subset_name)\n",
    "\n",
    "# Iterate to each prompt templates\n",
    "for prompt_id in tqdm(prompt.templates):\n",
    "    template_name = prompt.templates[prompt_id].name\n",
    "\n",
    "    for dataset_key in dset.keys():\n",
    "        for example in dset[dataset_key]:\n",
    "            data_details = {\n",
    "                \"dataset_name\": dataset_name,\n",
    "                \"subset_name\": subset_name,\n",
    "                \"prompt_id\": prompt_id,\n",
    "                \"template_name\": template_name,\n",
    "                \"dataset_key\": dataset_key,\n",
    "            }\n",
    "            input = None\n",
    "            output = None\n",
    "\n",
    "            try:\n",
    "                render = prompt[template_name].apply(example)\n",
    "                if len(render) != 2:\n",
    "                    if len(render) == 1:\n",
    "                        input = render[0]\n",
    "\n",
    "                    logger.info(f\"Output not available for {data_details}.\")\n",
    "                    break\n",
    "                else:\n",
    "                    input = render[0]\n",
    "                    output = render[1]\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Exception occurred on {data_details}. Please rectify: {e}\")\n",
    "                break\n",
    "            \n",
    "            data_details[\"input\"] = input\n",
    "            data_details[\"output\"] = output\n",
    "\n",
    "            all_data.append(\n",
    "                data_details\n",
    "            )\n",
    "    \n",
    "df_ = pd.DataFrame(all_data)\n",
    "df_.to_csv(f\"{checkpoint_save_path}/{dataset_name}-{subset_name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "promptsource",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
