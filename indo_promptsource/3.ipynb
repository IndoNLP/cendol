{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ihza.mahendra/anaconda3/envs/promptsource/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-08-18 08:45:01 [INFO]: Input dataset_name: jadi_ide\n",
      "2023-08-18 08:45:01 [INFO]: Input subset_name: nusa\n",
      "2023-08-18 08:45:01 [DEBUG]: open file: /Users/ihza.mahendra/.cache/huggingface/datasets/jadi_ide/jadi_ide_nusantara_text/1.0.0/20a99eaa5b374f17ea2ba40067c7ed4461a7c53ba3dc522e3f61dc9f29d53916/dataset_info.json\n",
      "2023-08-18 08:45:01 [DEBUG]: open file: /Users/ihza.mahendra/.cache/huggingface/datasets/jadi_ide/jadi_ide_nusantara_text/1.0.0/20a99eaa5b374f17ea2ba40067c7ed4461a7c53ba3dc522e3f61dc9f29d53916/dataset_info.json\n",
      "2023-08-18 08:45:01 [INFO]: ============================================\n",
      "2023-08-18 08:45:01 [INFO]: ## DATASET INFO ##\n",
      "2023-08-18 08:45:01 [INFO]: Real dataset_name: jadi_ide\n",
      "2023-08-18 08:45:01 [INFO]: Real subset_name: jadi_ide_nusantara_text\n",
      "2023-08-18 08:45:01 [INFO]: dset.shape: {'train': (16498, 3)}\n",
      "2023-08-18 08:45:01 [INFO]: Example dataset: {'id': '0', 'text': 'sing kudu dimungsuhi kuwi udu manungsane nanging sifat ala kang ana njero atine oleh awake dhewe iki ora seneng marang kelakuan utawa sifat alane nanging aja gething sengit marang manungsane senajan kepiye wae iku isih sedulure dhewe sing tetep pantes didongakake kabecikane', 'label': 1}\n",
      "2023-08-18 08:45:01 [INFO]: ============================================\n",
      "100%|██████████| 10/10 [01:52<00:00, 11.24s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from promptsource.templates import DatasetTemplates\n",
    "# !pip install nusacrowd\n",
    "from nusacrowd import NusantaraConfigHelper\n",
    "import logging\n",
    "import argparse\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--dataset-name', help='Dataset name')\n",
    "# parser.add_argument('--subset-name', help='Subset name')\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# Set up the logger\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,  # Set the desired logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)\n",
    "    format='%(asctime)s [%(levelname)s]: %(message)s',  # Customize the log message format\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'  # Customize the date/time format\n",
    ")\n",
    "\n",
    "# Create a file handler to write logs into a file\n",
    "file_handler = logging.FileHandler('app.log')\n",
    "file_handler.setLevel(logging.DEBUG)  # Set the log level for the file handler\n",
    "\n",
    "# Create a formatter for the file handler (customize the log format for the file)\n",
    "file_formatter = logging.Formatter('%(asctime)s [%(levelname)s]: %(message)s', datefmt='%Y-%m-%d %H:%M:%S')\n",
    "file_handler.setFormatter(file_formatter)\n",
    "\n",
    "logger = logging.getLogger(\"IndoP3 Dataset Generation\")\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "conhelps = NusantaraConfigHelper()\n",
    "\n",
    "all_data = []\n",
    "checkpoint_save_path = \"generated_dataset\"\n",
    "\n",
    "dataset_name = \"jadi_ide\" #args.dataset_name\n",
    "subset_name = \"nusa\" #args.subset_name\n",
    "logger.info(f\"Input dataset_name: {dataset_name}\")\n",
    "logger.info(f\"Input subset_name: {subset_name}\")\n",
    "\n",
    "# Load dataset\n",
    "nusa_metadata = conhelps.filtered(lambda x: dataset_name in x.dataset_name and subset_name in x.config.name)[0]\n",
    "dataset_name = nusa_metadata.dataset_name\n",
    "subset_name = nusa_metadata.config.name\n",
    "dset = nusa_metadata.load_dataset()\n",
    "logger.info(\"============================================\")\n",
    "logger.info(f\"## DATASET INFO ##\")\n",
    "logger.info(f\"Real dataset_name: {dataset_name}\")\n",
    "logger.info(f\"Real subset_name: {subset_name}\")\n",
    "logger.info(f\"dset.shape: {dset.shape}\")\n",
    "example = dset[\"train\"][0]\n",
    "logger.info(f\"Example dataset: {example}\")\n",
    "logger.info(\"============================================\")\n",
    "\n",
    "\n",
    "# Load prompt\n",
    "prompt = DatasetTemplates(dataset_name, subset_name=subset_name)\n",
    "\n",
    "# Iterate to each prompt templates\n",
    "for prompt_id in tqdm(prompt.templates):\n",
    "    template_name = prompt.templates[prompt_id].name\n",
    "\n",
    "    for dataset_key in dset.keys():\n",
    "        for example in dset[dataset_key]:\n",
    "            data_details = {\n",
    "                \"dataset_name\": dataset_name,\n",
    "                \"subset_name\": subset_name,\n",
    "                \"prompt_id\": prompt_id,\n",
    "                \"template_name\": template_name,\n",
    "                \"dataset_key\": dataset_key,\n",
    "            }\n",
    "            input = None\n",
    "            output = None\n",
    "\n",
    "            try:\n",
    "                render = prompt[template_name].apply(example)\n",
    "                if len(render) != 2:\n",
    "                    if len(render) == 1:\n",
    "                        input = render[0]\n",
    "\n",
    "                    logger.info(f\"Output not available for {data_details}.\")\n",
    "                    break\n",
    "                else:\n",
    "                    input = render[0]\n",
    "                    output = render[1]\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Exception occurred on {data_details}. Please rectify: {e}\")\n",
    "                break\n",
    "            \n",
    "            data_details[\"input\"] = input\n",
    "            data_details[\"output\"] = output\n",
    "\n",
    "            all_data.append(\n",
    "                data_details\n",
    "            )\n",
    "    \n",
    "df_ = pd.DataFrame(all_data)\n",
    "df_.to_csv(f\"{checkpoint_save_path}/{dataset_name}-{subset_name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "promptsource",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
