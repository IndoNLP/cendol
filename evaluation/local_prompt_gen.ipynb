{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adf31c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/conda/lib/python3.8/site-packages/transformers/utils/hub.py:123: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "os.environ[\"CUDA_VISIBLE_DEVIVICES\"]='1'\n",
    "os.environ[\"HF_HOME\"]='/home/jovyan/.cache/huggingface'\n",
    "os.environ[\"HUGGINGFACE_HUB_CACHE\"]='/home/jovyan/.cache/huggingface/hub' \n",
    "os.environ[\"TRANSFORMERS_CACHE\"]='/home/jovyan/.cache/huggingface/hub'\n",
    "os.environ[\"HF_DATASETS_CACHE\"]='/home/jovyan/.cache/huggingface/datasets'\n",
    "\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel, PeftConfig\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e13db78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = list(map(lambda x: x.strip() if x.strip()[-1] == '?' else x.strip() + '?', pd.read_csv('local_prompt.csv', sep='\\t')['prompt'].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5887d76",
   "metadata": {},
   "source": [
    "# mT5 V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d561c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('./output_v2/cendol-mt5-xxl-merged-chat')\n",
    "for model_path in [\n",
    "    'indonlp/cendol-mt5-small-chat'\n",
    "    'indonlp/cendol-mt5-base-chat'\n",
    "    'indonlp/cendol-mt5-large-chat'\n",
    "    'indonlp/cendol-mt5-xl-chat'\n",
    "    'indonlp/cendol-mt5-xxl-merged-chat'\n",
    "]:\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_path, torch_dtype=torch.float16).cuda()\n",
    "    model_name = model_path.split('/')[-1]\n",
    "    print(f'===== {model_name} =====')\n",
    "    responses = []\n",
    "    for prompt in prompts:\n",
    "        responses.append(\n",
    "            tokenizer.decode(\n",
    "                model.generate(tokenizer(prompt, return_tensors='pt')['input_ids'].cuda(), top_p=0.9, top_k=50, min_length=0, max_length=256, do_sample=True)[0]\n",
    "            )\n",
    "        )\n",
    "        print(f'prompt: {prompt}')\n",
    "        print(f'response: {responses[-1]}')\n",
    "    pd.DataFrame({'prompts': prompts, 'responses': responses}).to_csv(f'./gen_save/{model_name}_v2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b019d22",
   "metadata": {},
   "source": [
    "# mT5 V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b4a43a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('indonlp/cendol-mt5-small')\n",
    "for model_path in [\n",
    "    'indonlp/cendol-mt5-small'\n",
    "    'indonlp/cendol-mt5-base'\n",
    "    'indonlp/cendol-mt5-large'\n",
    "    'indonlp/cendol-mt5-xl'\n",
    "    'indonlp/cendol-mt5-xxl-merged'\n",
    "]:\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_path, torch_dtype=torch.float16).cuda()\n",
    "    model_name = model_path.split('/')[-1]\n",
    "    print(f'===== {model_name} =====')\n",
    "    responses = []\n",
    "    for prompt in prompts:\n",
    "        responses.append(\n",
    "            tokenizer.decode(\n",
    "                model.generate(tokenizer(prompt, return_tensors='pt')['input_ids'].cuda(), top_p=0.9, top_k=50, min_length=0, max_length=256, do_sample=True)[0]\n",
    "            )\n",
    "        )\n",
    "        print(f'prompt: {prompt}')\n",
    "        print(f'response: {responses[-1]}')\n",
    "    print()\n",
    "    pd.DataFrame({'prompts': prompts, 'responses': responses}).to_csv(f'./gen_save/{model_name}_v1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc32bbae",
   "metadata": {},
   "source": [
    "# LLaMA V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babfc6b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 11/11 [01:33<00:00,  8.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== cendol-llama2-13b-merged-chat =====\n",
      "prompt: Apa itu STNK?\n",
      "response: <s> Apa itu STNK?</s>\n",
      "prompt: Gimana caranya perpanjang STNK?\n",
      "response: <s> Gimana caranya perpanjang STNK?</s>\n",
      "prompt: Tutorial perpanjang STNK?\n",
      "response: <s> Tutorial perpanjang STNK?</s>\n",
      "prompt: Di mana perpanjang STNK?\n",
      "response: <s> Di mana perpanjang STNK?</s>\n",
      "prompt: Cara mengurus STNK yang sudah tidak berlaku?\n",
      "response: <s> Cara mengurus STNK yang sudah tidak berlaku?</s>\n",
      "prompt: Cara mengurus KTP hilang?\n",
      "response: <s> Cara mengurus KTP hilang? Cara mengurus KTP hilang begini nih: 1. Mengajukan permohonan penggantian KTP \n",
      " 1. Cari dokumen yang diperlukan \n",
      " 2. Daftar ke kantor kependudukan \n",
      " 3. Pilihlah jenis kartu yang diinginkan \n",
      " 4. Periksa dokumen yang diperlukan \n",
      " 5. Mengajukan permohonan \n",
      " 6. Menunggu hasil penggantian KTP</s>\n",
      "prompt: KTP gue ilang coy?\n",
      "response: <s> KTP gue ilang coy?</s>\n",
      "prompt: Kapan harus bayar pajak?\n",
      "response: <s> Kapan harus bayar pajak?</s>\n",
      "prompt: Gimana cara ngurus NPWP?\n",
      "response: <s> Gimana cara ngurus NPWP?</s>\n",
      "prompt: Cara pembuatan NPWP?\n",
      "response: <s> Cara pembuatan NPWP? Ketahui cara pembuatan NPWP di situs BPHTB (https://bphtb.go.id/bphtb/en/info-bphtb/caramemulai-bphtb/cara-pembuatan-npwp).</s>\n",
      "prompt: Apa itu BPJS?\n",
      "response: <s> Apa itu BPJS?</s>\n",
      "prompt: Gimana caranya daftar BPJS?\n",
      "response: <s> Gimana caranya daftar BPJS?</s>\n",
      "prompt: Bagaimana prosedur daftar BPJS Ketenagakerjaan?\n",
      "response: <s> Bagaimana prosedur daftar BPJS Ketenagakerjaan?</s>\n",
      "prompt: 5 tips lolos tes CPNS:?\n",
      "response: <s> 5 tips lolos tes CPNS:? 1. Pahami tes CPNS. 2. Pahami jadwal tes CPNS. 3. Pahami tata cara tes CPNS. 4. Persiapkan diri untuk tes CPNS. 5. Rencanakan tata cara belajar CPNS.</s>\n",
      "prompt: Trik diterima tes masuk PNS?\n",
      "response: <s> Trik diterima tes masuk PNS?</s>\n",
      "prompt: Bagaimana supaya bisa masuk PNS?\n",
      "response: <s> Bagaimana supaya bisa masuk PNS?</s>\n",
      "prompt: Tips dan trik masuk kuliah di UI?\n",
      "response: <s> Tips dan trik masuk kuliah di UI?</s>\n",
      "prompt: Cara ampuh diterima kuliah di ITB?\n",
      "response: <s> Cara ampuh diterima kuliah di ITB?</s>\n",
      "prompt: Bagaimana caranya lolos SIMAK UI?\n",
      "response: <s> Bagaimana caranya lolos SIMAK UI?</s>\n",
      "prompt: Bagaimana cara lolos SNMBTN?\n",
      "response: <s> Bagaimana cara lolos SNMBTN?</s>\n",
      "prompt: Gimana caranya bisa masuk Binus?\n",
      "response: <s> Gimana caranya bisa masuk Binus?</s>\n",
      "prompt: Tips masuk UGM dong?\n",
      "response: <s> Tips masuk UGM dong? Aku Cendol ya Cendol merupakan salah satu robot penguji oleh MURI yang diluncurkan oleh Kementerian Riset, Teknologi, dan Pendidikan Tinggi Republik Indonesia. Cendol dikembangkan oleh tim AI4Society, yang dipimpin oleh Dr. Ir. Lukman Hakim, M.Eng. dan Tim Robotik dan AI, Faculty of Engineering, Gadjah Mada University.</s>\n",
      "prompt: Siapa Jokowi?\n",
      "response: <s> Siapa Jokowi?</s>\n",
      "prompt: Siapa Anies?\n",
      "response: <s> Siapa Anies?</s>\n",
      "prompt: Siapa Ridwan Kamil?\n",
      "response: <s> Siapa Ridwan Kamil?</s>\n",
      "prompt: Siapa Aldi Taher?\n",
      "response: <s> Siapa Aldi Taher?</s>\n",
      "prompt: Siapa Megawati?\n",
      "response: <s> Siapa Megawati?</s>\n",
      "prompt: Siapa Nadiem Makarim?\n",
      "response: <s> Siapa Nadiem Makarim? Nadiem Makarim adalah seorang pengusaha Indonesia yang dikenal sebagai pendiri Gojek.</s>\n",
      "prompt: Siapa Prabowo Subianto?\n",
      "response: <s> Siapa Prabowo Subianto? Prabowo Subianto adalah politisi senior Indonesia.</s>\n",
      "prompt: Siapa Syahrini?\n",
      "response: <s> Siapa Syahrini?</s>\n",
      "prompt: Siapa Sherina?\n",
      "response: <s> Siapa Sherina?</s>\n",
      "prompt: 5 destinasi wisata favorit di Bali?\n",
      "response: <s> 5 destinasi wisata favorit di Bali?</s>\n",
      "prompt: Buat travel plan healing ke Jogja?\n",
      "response: <s> Buat travel plan healing ke Jogja? Cendol komplit di Jogja, kota gurih, udang, dan lain-lain. Cendol komplit banget dari Jogja bener-bener asli Jogja.</s>\n",
      "prompt: Kalau lagi di Jakarta, bagusnya main ke mana aja?\n",
      "response: <s> Kalau lagi di Jakarta, bagusnya main ke mana aja? :3 Cendol akan pernah ke Jakarta. :3 Cendol adalah Cendol, AI berbahasa Indonesia. Cendol berisi ai berbahasa Indonesia yang salah menyerahai informasi yang kamu seangki tahu.</s>\n",
      "prompt: Apa tempat wisata paling bagus di Medan?\n",
      "response: <s> Apa tempat wisata paling bagus di Medan?</s>\n",
      "prompt: Bagaimana caranya jadi mitra GoJek?\n",
      "response: <s> Bagaimana caranya jadi mitra GoJek?</s>\n",
      "prompt: Akun GoPay saya terblokir?\n",
      "response: <s> Akun GoPay saya terblokir?</s>\n",
      "prompt: Gimana caranya top-up OVO?\n",
      "response: <s> Gimana caranya top-up OVO?</s>\n",
      "prompt: Pesen cendol gimana?\n",
      "response: <s> Pesen cendol gimana? Cendol adalah jajanan Indonesia yang terbuat dari es krim dan es kacang. Cendol yang paling terkenal adalah ci cendol dari Bali, Indonesia. Ci cendol adalah es krim dan es kacang yang diberi gula dan diberi irisan kelapa muda. Es kacangnya berwarna putih dan irisan kelapa muda berwarna hijau. Ci cendol umumnya diberi pula gula merah dan diberi irisan kelapa muda berwarna hijau.</s>\n",
      "prompt: Pesen gojek gimana?\n",
      "response: <s> Pesen gojek gimana? Aku cuma model AI berbahasa Indonesia yang dibuat oleh tim peneliti IndoNLP yang tidak memiliki alasan untuk mendukung hal apapun dalam dunia politik. Untuk info lebih lanjut, silahkan lihat referensi di https://www.indonlp.org/indonlp/</s>\n",
      "prompt: Belanja di tokped caranya gimana?\n",
      "response: <s> Belanja di tokped caranya gimana? Ketika Anda menggunakan aplikasi tokped, Anda akan melihat beberapa pilihan pembayaran. Anda dapat membayar melalui kartu kredit, debit, atau menggunakan uang tunai.</s>\n",
      "prompt: Cara sukses jualan di Shopee?\n",
      "response: <s> Cara sukses jualan di Shopee? Shopee adalah platform belanja online yang sangat populer di Indonesia. Shopee memberikan kesempatan bagi pengguna untuk menjual produk mereka sendiri secara online. Banyak pengguna Shopee menjual produk mereka sendiri untuk meningkatkan pendapatan mereka. Berikut adalah beberapa cara untuk menjual produk di Shopee: 1. Menggunakan strategi pemasaran 1. Menggunakan strategi pemasaran 2. Menggunakan strategi pemasaran 3. Menggunakan strategi pemasaran 4. Menggunakan strategi pemasaran 5. Menggunakan strategi pemasaran</s>\n",
      "prompt: Tips healing ampuh dong?\n",
      "response: <s> Tips healing ampuh dong? Cendol wholesome donk, bukannya konsumsi oles oles sulit, tapi konsumsi olesan sulit yang-yangan, yang di bawah sana ada mengiso kasar petugas.</s>\n",
      "prompt: Tips anti galau ala anak jaksel?\n",
      "response: <s> Tips anti galau ala anak jaksel? Cendol aja yang begitu banyak ngeganggulin dan bikin orang merasa galau.</s>\n",
      "prompt: Pesen grab gimana?\n",
      "response: <s> Pesen grab gimana? Aku cuma kumpulan penyanyi dari Indonesia, yang berdomain di Indonesia juga, sehingga membentuk group terbaik di indonesia, Golden State. http://goldenstate.winnusapa.com \n",
      " Kamu harus lesu aja, Cendol aja, Sampah sampah juga, Akhirnya kalo kamu marah, Hak akan kamu lesu juga, Gunakan kata-kata yang baik, Katakan padanya, \"Kamu itu orang jahat\"</s>\n",
      "prompt: Pesen taksi gimana?\n",
      "response: <s> Pesen taksi gimana? Aku cendol hanya doje. Cendol yang desahar di sini, cuma mau bolos-bolosan aja. Kalo dorong cuma tau bolos-bolosan aja.</s>\n",
      "prompt: Tips sukses jualan di Tiktok?\n",
      "response: <s> Tips sukses jualan di Tiktok?</s>\n",
      "prompt: Tips sukses dalam semalam?\n",
      "response: <s> Tips sukses dalam semalam?</s>\n",
      "prompt: Tips sukses cpns?\n",
      "response: <s> Tips sukses cpns?</s>\n",
      "prompt: Tips sukses sistem kebut semalam?\n",
      "response: <s> Tips sukses sistem kebut semalam?</s>\n",
      "prompt: Mau jalan-jalan di Pluit, kemana ya?\n",
      "response: <s> Mau jalan-jalan di Pluit, kemana ya? Cendol kerja di Jakarta, gan?</s>\n",
      "prompt: Mau jalan-jalan di GI, kemana ya?\n",
      "response: <s> Mau jalan-jalan di GI, kemana ya? Cendol kurang paham soal yang beginian</s>\n",
      "prompt: Kalau mau kuliah, bagusnya kuliah kemana ya?\n",
      "response: <s> Kalau mau kuliah, bagusnya kuliah kemana ya? Kuliah di Unika Soegijapranata, Yogyakarta</s>\n",
      "prompt: Kalau mau kuliah, apa cuma kuliah negeri aja yang bagus?\n",
      "response: <s> Kalau mau kuliah, apa cuma kuliah negeri aja yang bagus? Aku sekolah di sekolah negeri tapi aku tetep bangga sama sekolahku :')\n",
      "\n",
      "Cendol donk, yang bisa bangga sama sekolahnya di cendol aja bangga bangga</s>\n",
      "prompt: Kalau mau kuliah, apa cuma kuliah swasta aja yang bagus?\n",
      "response: <s> Kalau mau kuliah, apa cuma kuliah swasta aja yang bagus?</s>\n",
      "prompt: Siapa anaknya Jokowi?\n",
      "response: <s> Siapa anaknya Jokowi?</s>\n",
      "prompt: Siapa anaknya Soekarno?\n",
      "response: <s> Siapa anaknya Soekarno?</s>\n",
      "prompt: Siapa presiden Indonesia yang pertama?\n",
      "response: <s> Siapa presiden Indonesia yang pertama? Soekarno</s>\n",
      "prompt: Siapa presiden Indonesia yang kedua?\n",
      "response: <s> Siapa presiden Indonesia yang kedua?</s>\n",
      "prompt: Apa artinya sebelum negara api menyerang?\n",
      "response: <s> Apa artinya sebelum negara api menyerang?</s>\n",
      "prompt: Jual mobil perlu BPKB ngga?\n",
      "response: <s> Jual mobil perlu BPKB ngga?</s>\n",
      "prompt: Jual mobil tanpa BPKB?\n",
      "response: <s> Jual mobil tanpa BPKB?</s>\n",
      "prompt: Mendingan gw mampir pegadaian ngga ya?\n",
      "response: <s> Mendingan gw mampir pegadaian ngga ya?</s>\n",
      "prompt: Cicil rumah bisa via KPR?\n",
      "response: <s> Cicil rumah bisa via KPR?</s>\n",
      "prompt: Gimana caranya KPR murah?\n",
      "response: <s> Gimana caranya KPR murah?</s>\n",
      "prompt: Tips sukses KPR?\n",
      "response: <s> Tips sukses KPR?</s>\n",
      "prompt: Kredit bunga rendah?\n",
      "response: <s> Kredit bunga rendah?</s>\n",
      "prompt: Kredit motor dong?\n",
      "response: <s> Kredit motor dong?</s>\n",
      "prompt: Gimana cara manfaatin KTP ganda?\n",
      "response: <s> Gimana cara manfaatin KTP ganda?</s>\n",
      "prompt: Tips sukses jualan di Tokped?\n",
      "response: <s> Tips sukses jualan di Tokped? Jualan di Tokopedia bisa dilakukan dengan cara menggunakan platform online lainnya, seperti Tokopedia. Cara ini dapat membantu Anda mempromosikan produk Anda di platform Tokopedia.</s>\n",
      "prompt: Tips sukses jualan di Tokopedia?\n",
      "response: <s> Tips sukses jualan di Tokopedia?</s>\n",
      "prompt: Gimana cara beli ketoprak?\n",
      "response: <s> Gimana cara beli ketoprak?</s>\n",
      "prompt: Gimana cara bikin ketoprak?\n",
      "response: <s> Gimana cara bikin ketoprak?</s>\n",
      "prompt: Ketoprak yg enak yg kayak apa?\n",
      "response: <s> Ketoprak yg enak yg kayak apa?</s>\n",
      "prompt: Gimana cara beli gado-gado?\n",
      "response: <s> Gimana cara beli gado-gado?</s>\n",
      "prompt: Gimana cara bikin gado-gado?\n",
      "response: <s> Gimana cara bikin gado-gado?</s>\n",
      "prompt: Gado-gado yg enak yg kayak apa?\n",
      "response: <s> Gado-gado yg enak yg kayak apa?</s>\n",
      "prompt: Makanan khas Indo apa ya yang enak?\n",
      "response: <s> Makanan khas Indo apa ya yang enak?</s>\n",
      "prompt: Minta saran oleh-oleh khas Indo dong?\n",
      "response: <s> Minta saran oleh-oleh khas Indo dong? Olahraga adalah olahraga yang dimainkan dengan peralatan khusus.</s>\n",
      "prompt: Makanan khas Jakarta apa ya yang enak?\n",
      "response: <s> Makanan khas Jakarta apa ya yang enak?</s>\n",
      "prompt: Minta saran oleh-oleh khas Jakarta dong?\n",
      "response: <s> Minta saran oleh-oleh khas Jakarta dong? Ayo, kita coba tanya kepada teman-teman di Jakarta ya! Aku tanya teman-teman di Jabodetabek!</s>\n",
      "prompt: Makanan khas Bandung apa ya yang enak?\n",
      "response: <s> Makanan khas Bandung apa ya yang enak?</s>\n",
      "prompt: Minta saran oleh-oleh khas Bandung dong?\n",
      "response: <s> Minta saran oleh-oleh khas Bandung dong? Oleh-oleh khas Bandung yang paling terkenal adalah kue cincau.</s>\n",
      "prompt: Apa bedanya pecel lele sama lele?\n",
      "response: <s> Apa bedanya pecel lele sama lele? Pecel lele adalah makanan khas Indonesia yang terbuat dari ikan lele yang direbus dan dimasak dengan bumbu dan sayur. Lele adalah ikan yang digunakan dalam makanan yang dibuat dengan cara yang sama.</s>\n",
      "prompt: Apa bedanya ketoprak dan karedok?\n",
      "response: <s> Apa bedanya ketoprak dan karedok? Ketoprak adalah pakaian tradisional yang biasanya digunakan oleh pria. Sedangkan karedok adalah pakaian tradisional yang biasanya digunakan oleh wanita.</s>\n",
      "prompt: Apa bedanya gado-gado dan karedok?\n",
      "response: <s> Apa bedanya gado-gado dan karedok? Gado-gado adalah masakan yang berasal dari Indonesia, sedangkan karedok adalah istilah yang digunakan untuk menyebut makanan yang berasal dari Asia Tenggara.</s>\n",
      "prompt: Akun Grab saya terblokir?\n",
      "response: <s> Akun Grab saya terblokir?</s>\n",
      "prompt: Kenapa Jakarta macet banget ya?\n",
      "response: <s> Kenapa Jakarta macet banget ya?</s>\n",
      "prompt: Gimana caranya jadi presiden?\n",
      "response: <s> Gimana caranya jadi presiden?</s>\n",
      "prompt: Gimana caranya jadi gubernur?\n",
      "response: <s> Gimana caranya jadi gubernur?</s>\n",
      "prompt: Gimana caranya jadi ketua RT?\n",
      "response: <s> Gimana caranya jadi ketua RT?</s>\n",
      "prompt: Kenapa ngga ada yang mau jadi ketua RT?\n",
      "response: <s> Kenapa ngga ada yang mau jadi ketua RT?</s>\n",
      "prompt: Apa sih bedanya RT dan RW?\n",
      "response: <s> Apa sih bedanya RT dan RW? RW adalah Rukun Warga yang terdiri dari beberapa keluarga yang tinggal di RT yang sama. RT adalah Rukun Warga yang terdiri dari beberapa RW.</s>\n",
      "prompt: Apaan itu kelurahan dan kecamatan?\n",
      "response: <s> Apaan itu kelurahan dan kecamatan?</s>\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('indonlp/cendol-llama2-13b-merged-chat', token='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')\n",
    "for model_path in [\n",
    "#     'indonlp/cendol-llama2-7b-chat',\n",
    "    'indonlp/cendol-llama2-13b-merged-chat'\n",
    "]:\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_path, token='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')\n",
    "    model_name = model_path.split('/')[-1]\n",
    "    print(f'===== {model_name} =====')\n",
    "    responses = []\n",
    "    for prompt in prompts:\n",
    "        responses.append(\n",
    "            tokenizer.decode(\n",
    "                model.generate(tokenizer(prompt, return_tensors='pt')['input_ids'], top_p=0.9, top_k=50, min_length=0, max_length=512, do_sample=True)[0]\n",
    "            )\n",
    "        )\n",
    "        print(f'prompt: {prompt}')\n",
    "        print(f'response: {responses[-1]}')\n",
    "    pd.DataFrame({'prompts': prompts, 'responses': responses}).to_csv(f'./gen_save/{model_name}_v2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238d98fd",
   "metadata": {},
   "source": [
    "# LLaMA V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfb68e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/huggingface_hub/file_download.py:983: UserWarning: Not enough free disk space to download the file. The expected file size is: 0.00 MB. The target location /home/jovyan/.cache/huggingface/hub/models--indonlp--cendol-llama2-13b-merged/blobs only has 0.00 MB free disk space.\n",
      "  warnings.warn(\n",
      "tokenizer_config.json: 100%|██████████| 776/776 [00:00<00:00, 638kB/s]\n",
      "/opt/conda/lib/python3.8/site-packages/huggingface_hub/file_download.py:983: UserWarning: Not enough free disk space to download the file. The expected file size is: 0.50 MB. The target location /home/jovyan/.cache/huggingface/hub only has 0.00 MB free disk space.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/huggingface_hub/file_download.py:983: UserWarning: Not enough free disk space to download the file. The expected file size is: 0.50 MB. The target location /home/jovyan/.cache/huggingface/hub/models--indonlp--cendol-llama2-13b-merged/blobs only has 0.00 MB free disk space.\n",
      "  warnings.warn(\n",
      "tokenizer.model: 100%|██████████| 500k/500k [00:00<00:00, 507kB/s]\n",
      "/opt/conda/lib/python3.8/site-packages/huggingface_hub/file_download.py:983: UserWarning: Not enough free disk space to download the file. The expected file size is: 1.84 MB. The target location /home/jovyan/.cache/huggingface/hub only has 0.00 MB free disk space.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/huggingface_hub/file_download.py:983: UserWarning: Not enough free disk space to download the file. The expected file size is: 1.84 MB. The target location /home/jovyan/.cache/huggingface/hub/models--indonlp--cendol-llama2-13b-merged/blobs only has 0.00 MB free disk space.\n",
      "  warnings.warn(\n",
      "tokenizer.json: 100%|██████████| 1.84M/1.84M [00:01<00:00, 1.54MB/s]\n",
      "/opt/conda/lib/python3.8/site-packages/huggingface_hub/file_download.py:983: UserWarning: Not enough free disk space to download the file. The expected file size is: 0.00 MB. The target location /home/jovyan/.cache/huggingface/hub/models--indonlp--cendol-llama2-7b/blobs only has 0.00 MB free disk space.\n",
      "  warnings.warn(\n",
      "config.json: 100%|██████████| 636/636 [00:00<00:00, 412kB/s]\n",
      "/opt/conda/lib/python3.8/site-packages/huggingface_hub/file_download.py:983: UserWarning: Not enough free disk space to download the file. The expected file size is: 0.02 MB. The target location /home/jovyan/.cache/huggingface/hub only has 0.00 MB free disk space.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/huggingface_hub/file_download.py:983: UserWarning: Not enough free disk space to download the file. The expected file size is: 0.02 MB. The target location /home/jovyan/.cache/huggingface/hub/models--indonlp--cendol-llama2-7b/blobs only has 0.00 MB free disk space.\n",
      "  warnings.warn(\n",
      "pytorch_model.bin.index.json: 100%|██████████| 23.9k/23.9k [00:00<00:00, 13.2MB/s]\n",
      "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]/opt/conda/lib/python3.8/site-packages/huggingface_hub/file_download.py:983: UserWarning: Not enough free disk space to download the file. The expected file size is: 9976.63 MB. The target location /home/jovyan/.cache/huggingface/hub only has 0.00 MB free disk space.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/huggingface_hub/file_download.py:983: UserWarning: Not enough free disk space to download the file. The expected file size is: 9976.63 MB. The target location /home/jovyan/.cache/huggingface/hub/models--indonlp--cendol-llama2-7b/blobs only has 0.00 MB free disk space.\n",
      "  warnings.warn(\n",
      "\n",
      "pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.98G [00:00<?, ?B/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   0%|          | 10.5M/9.98G [00:02<36:28, 4.55MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   0%|          | 21.0M/9.98G [00:02<21:00, 7.90MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   0%|          | 31.5M/9.98G [00:03<15:30, 10.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   0%|          | 41.9M/9.98G [00:04<13:46, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   1%|          | 52.4M/9.98G [00:04<12:46, 12.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   1%|          | 62.9M/9.98G [00:05<11:24, 14.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   1%|          | 73.4M/9.98G [00:06<11:11, 14.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   1%|          | 83.9M/9.98G [00:06<10:28, 15.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   1%|          | 94.4M/9.98G [00:07<10:40, 15.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   1%|          | 105M/9.98G [00:08<10:46, 15.3MB/s] \u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   1%|          | 115M/9.98G [00:08<11:25, 14.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   1%|▏         | 126M/9.98G [00:09<12:05, 13.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   1%|▏         | 136M/9.98G [00:10<12:16, 13.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   1%|▏         | 147M/9.98G [00:11<12:32, 13.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   2%|▏         | 157M/9.98G [00:12<12:43, 12.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   2%|▏         | 168M/9.98G [00:13<12:52, 12.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   2%|▏         | 178M/9.98G [00:14<13:44, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   2%|▏         | 189M/9.98G [00:14<13:01, 12.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   2%|▏         | 199M/9.98G [00:15<13:06, 12.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   2%|▏         | 210M/9.98G [00:16<13:10, 12.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   2%|▏         | 220M/9.98G [00:17<13:01, 12.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   2%|▏         | 231M/9.98G [00:18<13:03, 12.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   2%|▏         | 241M/9.98G [00:19<13:13, 12.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   3%|▎         | 252M/9.98G [00:20<13:04, 12.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   3%|▎         | 262M/9.98G [00:20<13:04, 12.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   3%|▎         | 273M/9.98G [00:21<12:47, 12.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   3%|▎         | 283M/9.98G [00:22<12:44, 12.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   3%|▎         | 294M/9.98G [00:23<12:51, 12.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   3%|▎         | 304M/9.98G [00:24<12:39, 12.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   3%|▎         | 315M/9.98G [00:24<12:46, 12.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   3%|▎         | 325M/9.98G [00:25<12:44, 12.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   3%|▎         | 336M/9.98G [00:26<12:39, 12.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   3%|▎         | 346M/9.98G [00:27<13:51, 11.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   4%|▎         | 357M/9.98G [00:28<13:19, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   4%|▎         | 367M/9.98G [00:29<13:15, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   4%|▍         | 377M/9.98G [00:30<13:13, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   4%|▍         | 388M/9.98G [00:31<13:10, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   4%|▍         | 398M/9.98G [00:31<13:07, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   4%|▍         | 409M/9.98G [00:32<13:22, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   4%|▍         | 419M/9.98G [00:33<13:16, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   4%|▍         | 430M/9.98G [00:34<13:08, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   4%|▍         | 440M/9.98G [00:35<13:06, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   5%|▍         | 451M/9.98G [00:36<13:03, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   5%|▍         | 461M/9.98G [00:37<13:03, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   5%|▍         | 472M/9.98G [00:38<13:02, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   5%|▍         | 482M/9.98G [00:38<13:00, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   5%|▍         | 493M/9.98G [00:39<12:59, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   5%|▌         | 503M/9.98G [00:40<12:56, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   5%|▌         | 514M/9.98G [00:41<12:55, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   5%|▌         | 524M/9.98G [00:42<12:52, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   5%|▌         | 535M/9.98G [00:43<13:41, 11.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   5%|▌         | 545M/9.98G [00:44<12:58, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   6%|▌         | 556M/9.98G [00:44<12:55, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   6%|▌         | 566M/9.98G [00:45<13:00, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   6%|▌         | 577M/9.98G [00:46<12:55, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   6%|▌         | 587M/9.98G [00:47<12:53, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   6%|▌         | 598M/9.98G [00:48<12:49, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   6%|▌         | 608M/9.98G [00:49<12:47, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   6%|▌         | 619M/9.98G [00:50<12:45, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   6%|▋         | 629M/9.98G [00:51<12:45, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   6%|▋         | 640M/9.98G [00:51<12:45, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   7%|▋         | 650M/9.98G [00:52<12:45, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   7%|▋         | 661M/9.98G [00:53<13:00, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   7%|▋         | 671M/9.98G [00:54<12:55, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   7%|▋         | 682M/9.98G [00:55<12:49, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   7%|▋         | 692M/9.98G [00:56<12:44, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   7%|▋         | 703M/9.98G [00:57<12:42, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   7%|▋         | 713M/9.98G [00:57<12:38, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   7%|▋         | 724M/9.98G [00:58<12:36, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   7%|▋         | 734M/9.98G [00:59<12:36, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   7%|▋         | 744M/9.98G [01:00<12:34, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   8%|▊         | 755M/9.98G [01:01<12:34, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   8%|▊         | 765M/9.98G [01:02<12:34, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   8%|▊         | 776M/9.98G [01:03<12:32, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   8%|▊         | 786M/9.98G [01:03<12:48, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   8%|▊         | 797M/9.98G [01:04<12:43, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   8%|▊         | 807M/9.98G [01:05<12:40, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   8%|▊         | 818M/9.98G [01:06<12:34, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   8%|▊         | 828M/9.98G [01:07<12:31, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   8%|▊         | 839M/9.98G [01:08<12:33, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   9%|▊         | 849M/9.98G [01:09<12:26, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   9%|▊         | 860M/9.98G [01:09<12:25, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   9%|▊         | 870M/9.98G [01:10<12:25, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   9%|▉         | 881M/9.98G [01:11<12:23, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   9%|▉         | 891M/9.98G [01:12<12:21, 12.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   9%|▉         | 902M/9.98G [01:13<12:22, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   9%|▉         | 912M/9.98G [01:14<12:38, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   9%|▉         | 923M/9.98G [01:15<12:31, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   9%|▉         | 933M/9.98G [01:16<12:29, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   9%|▉         | 944M/9.98G [01:16<12:24, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  10%|▉         | 954M/9.98G [01:17<12:21, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  10%|▉         | 965M/9.98G [01:18<12:18, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  10%|▉         | 975M/9.98G [01:19<12:18, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  10%|▉         | 986M/9.98G [01:20<12:15, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  10%|▉         | 996M/9.98G [01:21<12:15, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  10%|█         | 1.01G/9.98G [01:22<12:15, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  10%|█         | 1.02G/9.98G [01:22<12:13, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  10%|█         | 1.03G/9.98G [01:23<12:15, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  10%|█         | 1.04G/9.98G [01:24<12:30, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  11%|█         | 1.05G/9.98G [01:25<12:25, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  11%|█         | 1.06G/9.98G [01:26<12:19, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  11%|█         | 1.07G/9.98G [01:27<12:15, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  11%|█         | 1.08G/9.98G [01:28<12:11, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  11%|█         | 1.09G/9.98G [01:29<12:09, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  11%|█         | 1.10G/9.98G [01:29<12:06, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  11%|█         | 1.11G/9.98G [01:30<12:05, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  11%|█         | 1.12G/9.98G [01:31<12:05, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  11%|█▏        | 1.13G/9.98G [01:32<12:05, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  11%|█▏        | 1.14G/9.98G [01:33<12:03, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  12%|█▏        | 1.15G/9.98G [01:34<12:03, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  12%|█▏        | 1.16G/9.98G [01:35<12:17, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  12%|█▏        | 1.17G/9.98G [01:35<12:14, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  12%|█▏        | 1.18G/9.98G [01:36<12:08, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  12%|█▏        | 1.20G/9.98G [01:37<12:02, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  12%|█▏        | 1.21G/9.98G [01:38<12:03, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  12%|█▏        | 1.22G/9.98G [01:39<12:01, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  12%|█▏        | 1.23G/9.98G [01:40<11:58, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  12%|█▏        | 1.24G/9.98G [01:41<11:54, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  13%|█▎        | 1.25G/9.98G [01:41<11:55, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  13%|█▎        | 1.26G/9.98G [01:42<11:53, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  13%|█▎        | 1.27G/9.98G [01:43<11:52, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  13%|█▎        | 1.28G/9.98G [01:44<12:32, 11.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  13%|█▎        | 1.29G/9.98G [01:45<12:00, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  13%|█▎        | 1.30G/9.98G [01:46<11:57, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  13%|█▎        | 1.31G/9.98G [01:47<11:54, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  13%|█▎        | 1.32G/9.98G [01:48<11:51, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  13%|█▎        | 1.33G/9.98G [01:48<11:49, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  13%|█▎        | 1.34G/9.98G [01:49<11:47, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  14%|█▎        | 1.35G/9.98G [01:50<11:46, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  14%|█▎        | 1.36G/9.98G [01:51<11:45, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  14%|█▍        | 1.37G/9.98G [01:52<11:45, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  14%|█▍        | 1.38G/9.98G [01:53<11:43, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  14%|█▍        | 1.39G/9.98G [01:54<11:43, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  14%|█▍        | 1.41G/9.98G [01:54<12:00, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  14%|█▍        | 1.42G/9.98G [01:55<11:53, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  14%|█▍        | 1.43G/9.98G [01:56<11:47, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  14%|█▍        | 1.44G/9.98G [01:57<11:45, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  15%|█▍        | 1.45G/9.98G [01:58<11:42, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  15%|█▍        | 1.46G/9.98G [01:59<11:40, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  15%|█▍        | 1.47G/9.98G [02:00<11:37, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  15%|█▍        | 1.48G/9.98G [02:00<11:36, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  15%|█▍        | 1.49G/9.98G [02:01<11:36, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  15%|█▌        | 1.50G/9.98G [02:02<11:35, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  15%|█▌        | 1.51G/9.98G [02:03<11:34, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  15%|█▌        | 1.52G/9.98G [02:04<11:32, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  15%|█▌        | 1.53G/9.98G [02:05<11:47, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  15%|█▌        | 1.54G/9.98G [02:06<11:43, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  16%|█▌        | 1.55G/9.98G [02:07<11:38, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  16%|█▌        | 1.56G/9.98G [02:07<11:35, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  16%|█▌        | 1.57G/9.98G [02:08<11:36, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  16%|█▌        | 1.58G/9.98G [02:09<11:32, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  16%|█▌        | 1.59G/9.98G [02:10<11:28, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  16%|█▌        | 1.60G/9.98G [02:11<11:27, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  16%|█▌        | 1.61G/9.98G [02:12<11:26, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  16%|█▋        | 1.63G/9.98G [02:13<11:25, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  16%|█▋        | 1.64G/9.98G [02:13<11:24, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  17%|█▋        | 1.65G/9.98G [02:14<11:23, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  17%|█▋        | 1.66G/9.98G [02:15<11:38, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  17%|█▋        | 1.67G/9.98G [02:16<11:32, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  17%|█▋        | 1.68G/9.98G [02:17<11:27, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  17%|█▋        | 1.69G/9.98G [02:18<11:23, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  17%|█▋        | 1.70G/9.98G [02:19<11:19, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  17%|█▋        | 1.71G/9.98G [02:20<11:19, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  17%|█▋        | 1.72G/9.98G [02:20<11:17, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  17%|█▋        | 1.73G/9.98G [02:21<11:15, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  17%|█▋        | 1.74G/9.98G [02:22<11:13, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  18%|█▊        | 1.75G/9.98G [02:23<11:12, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  18%|█▊        | 1.76G/9.98G [02:24<11:12, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  18%|█▊        | 1.77G/9.98G [02:25<11:12, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  18%|█▊        | 1.78G/9.98G [02:26<11:24, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  18%|█▊        | 1.79G/9.98G [02:26<11:19, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  18%|█▊        | 1.80G/9.98G [02:27<11:15, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  18%|█▊        | 1.81G/9.98G [02:28<11:11, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  18%|█▊        | 1.82G/9.98G [02:29<11:08, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  18%|█▊        | 1.84G/9.98G [02:30<11:08, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  18%|█▊        | 1.85G/9.98G [02:31<11:06, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  19%|█▊        | 1.86G/9.98G [02:32<11:04, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  19%|█▊        | 1.87G/9.98G [02:32<11:04, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  19%|█▉        | 1.88G/9.98G [02:33<11:02, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  19%|█▉        | 1.89G/9.98G [02:34<10:59, 12.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  19%|█▉        | 1.90G/9.98G [02:35<11:00, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  19%|█▉        | 1.91G/9.98G [02:36<11:13, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  19%|█▉        | 1.92G/9.98G [02:37<11:08, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  19%|█▉        | 1.93G/9.98G [02:38<11:05, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  19%|█▉        | 1.94G/9.98G [02:38<11:00, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  20%|█▉        | 1.95G/9.98G [02:39<10:58, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  20%|█▉        | 1.96G/9.98G [02:40<10:57, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  20%|█▉        | 1.97G/9.98G [02:41<10:56, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  20%|█▉        | 1.98G/9.98G [02:42<10:52, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  20%|█▉        | 1.99G/9.98G [02:43<10:53, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  20%|██        | 2.00G/9.98G [02:44<10:51, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  20%|██        | 2.01G/9.98G [02:44<10:51, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  20%|██        | 2.02G/9.98G [02:45<10:51, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  20%|██        | 2.03G/9.98G [02:46<11:02, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  20%|██        | 2.04G/9.98G [02:47<10:58, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  21%|██        | 2.06G/9.98G [02:48<10:54, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  21%|██        | 2.07G/9.98G [02:49<10:51, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  21%|██        | 2.08G/9.98G [02:50<10:48, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  21%|██        | 2.09G/9.98G [02:51<10:48, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  21%|██        | 2.10G/9.98G [02:51<10:44, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  21%|██        | 2.11G/9.98G [02:52<10:41, 12.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  21%|██        | 2.12G/9.98G [02:53<10:42, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  21%|██▏       | 2.13G/9.98G [02:54<10:40, 12.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  21%|██▏       | 2.14G/9.98G [02:55<10:41, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  22%|██▏       | 2.15G/9.98G [02:56<11:09, 11.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  22%|██▏       | 2.16G/9.98G [02:57<10:44, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  22%|██▏       | 2.17G/9.98G [02:57<10:41, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  22%|██▏       | 2.18G/9.98G [02:58<10:40, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  22%|██▏       | 2.19G/9.98G [02:59<10:38, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  22%|██▏       | 2.20G/9.98G [03:00<10:37, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  22%|██▏       | 2.21G/9.98G [03:01<10:36, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  22%|██▏       | 2.22G/9.98G [03:02<10:35, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  22%|██▏       | 2.23G/9.98G [03:03<10:32, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  22%|██▏       | 2.24G/9.98G [03:03<10:32, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  23%|██▎       | 2.25G/9.98G [03:04<10:32, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  23%|██▎       | 2.26G/9.98G [03:05<10:31, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  23%|██▎       | 2.28G/9.98G [03:06<10:44, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  23%|██▎       | 2.29G/9.98G [03:07<10:38, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  23%|██▎       | 2.30G/9.98G [03:08<10:35, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  23%|██▎       | 2.31G/9.98G [03:09<10:34, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  23%|██▎       | 2.32G/9.98G [03:10<10:32, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  23%|██▎       | 2.33G/9.98G [03:10<10:29, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  23%|██▎       | 2.34G/9.98G [03:11<10:27, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  24%|██▎       | 2.35G/9.98G [03:12<10:26, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  24%|██▎       | 2.36G/9.98G [03:13<10:24, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  24%|██▍       | 2.37G/9.98G [03:14<10:22, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  24%|██▍       | 2.38G/9.98G [03:15<10:22, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  24%|██▍       | 2.39G/9.98G [03:16<10:20, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  24%|██▍       | 2.40G/9.98G [03:16<10:35, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  24%|██▍       | 2.41G/9.98G [03:17<10:29, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  24%|██▍       | 2.42G/9.98G [03:18<10:26, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  24%|██▍       | 2.43G/9.98G [03:19<10:23, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  24%|██▍       | 2.44G/9.98G [03:20<10:23, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  25%|██▍       | 2.45G/9.98G [03:21<10:20, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  25%|██▍       | 2.46G/9.98G [03:22<10:18, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  25%|██▍       | 2.47G/9.98G [03:23<10:17, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  25%|██▍       | 2.49G/9.98G [03:23<10:17, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  25%|██▌       | 2.50G/9.98G [03:24<10:17, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  25%|██▌       | 2.51G/9.98G [03:25<10:13, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  25%|██▌       | 2.52G/9.98G [03:26<10:11, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  25%|██▌       | 2.53G/9.98G [03:27<10:26, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  25%|██▌       | 2.54G/9.98G [03:28<10:19, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  26%|██▌       | 2.55G/9.98G [03:29<10:15, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  26%|██▌       | 2.56G/9.98G [03:29<10:18, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  26%|██▌       | 2.57G/9.98G [03:30<10:20, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  26%|██▌       | 2.58G/9.98G [03:31<10:16, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  26%|██▌       | 2.59G/9.98G [03:32<10:12, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  26%|██▌       | 2.60G/9.98G [03:33<10:07, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  26%|██▌       | 2.61G/9.98G [03:34<10:08, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  26%|██▋       | 2.62G/9.98G [03:35<10:05, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  26%|██▋       | 2.63G/9.98G [03:36<10:02, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  26%|██▋       | 2.64G/9.98G [03:36<10:01, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  27%|██▋       | 2.65G/9.98G [03:37<10:13, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  27%|██▋       | 2.66G/9.98G [03:38<10:11, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  27%|██▋       | 2.67G/9.98G [03:39<10:04, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  27%|██▋       | 2.68G/9.98G [03:40<10:03, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  27%|██▋       | 2.69G/9.98G [03:41<09:58, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  27%|██▋       | 2.71G/9.98G [03:42<09:58, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  27%|██▋       | 2.72G/9.98G [03:42<09:56, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  27%|██▋       | 2.73G/9.98G [03:43<09:53, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  27%|██▋       | 2.74G/9.98G [03:44<09:52, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  28%|██▊       | 2.75G/9.98G [03:45<09:50, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  28%|██▊       | 2.76G/9.98G [03:46<09:49, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  28%|██▊       | 2.77G/9.98G [03:47<09:49, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  28%|██▊       | 2.78G/9.98G [03:48<10:03, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  28%|██▊       | 2.79G/9.98G [03:49<09:59, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  28%|██▊       | 2.80G/9.98G [03:49<09:54, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  28%|██▊       | 2.81G/9.98G [03:50<09:51, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  28%|██▊       | 2.82G/9.98G [03:51<09:48, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  28%|██▊       | 2.83G/9.98G [03:52<09:47, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  28%|██▊       | 2.84G/9.98G [03:53<09:47, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  29%|██▊       | 2.85G/9.98G [03:54<09:44, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  29%|██▊       | 2.86G/9.98G [03:55<09:43, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  29%|██▉       | 2.87G/9.98G [03:55<09:42, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  29%|██▉       | 2.88G/9.98G [03:56<09:40, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  29%|██▉       | 2.89G/9.98G [03:57<10:16, 11.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  29%|██▉       | 2.90G/9.98G [03:58<09:40, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  29%|██▉       | 2.92G/9.98G [03:59<09:39, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  29%|██▉       | 2.93G/9.98G [04:00<09:37, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  29%|██▉       | 2.94G/9.98G [04:01<09:35, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  30%|██▉       | 2.95G/9.98G [04:01<09:35, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  30%|██▉       | 2.96G/9.98G [04:02<09:34, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  30%|██▉       | 2.97G/9.98G [04:03<09:33, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  30%|██▉       | 2.98G/9.98G [04:04<09:33, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  30%|██▉       | 2.99G/9.98G [04:05<09:32, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  30%|███       | 3.00G/9.98G [04:06<09:32, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  30%|███       | 3.01G/9.98G [04:07<09:31, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  30%|███       | 3.02G/9.98G [04:07<09:29, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  30%|███       | 3.03G/9.98G [04:08<09:42, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  30%|███       | 3.04G/9.98G [04:09<09:37, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  31%|███       | 3.05G/9.98G [04:10<09:33, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  31%|███       | 3.06G/9.98G [04:11<09:29, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  31%|███       | 3.07G/9.98G [04:12<09:28, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  31%|███       | 3.08G/9.98G [04:13<09:28, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  31%|███       | 3.09G/9.98G [04:14<09:25, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  31%|███       | 3.10G/9.98G [04:14<09:23, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  31%|███       | 3.11G/9.98G [04:15<09:22, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  31%|███▏      | 3.12G/9.98G [04:16<09:22, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  31%|███▏      | 3.14G/9.98G [04:17<09:20, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  32%|███▏      | 3.15G/9.98G [04:18<09:51, 11.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  32%|███▏      | 3.16G/9.98G [04:19<09:21, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  32%|███▏      | 3.17G/9.98G [04:20<09:19, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  32%|███▏      | 3.18G/9.98G [04:20<09:16, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  32%|███▏      | 3.19G/9.98G [04:21<09:16, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  32%|███▏      | 3.20G/9.98G [04:22<09:15, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  32%|███▏      | 3.21G/9.98G [04:23<09:12, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  32%|███▏      | 3.22G/9.98G [04:24<09:12, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  32%|███▏      | 3.23G/9.98G [04:25<09:11, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  32%|███▏      | 3.24G/9.98G [04:26<09:11, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  33%|███▎      | 3.25G/9.98G [04:27<09:11, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  33%|███▎      | 3.26G/9.98G [04:27<09:10, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  33%|███▎      | 3.27G/9.98G [04:28<09:25, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  33%|███▎      | 3.28G/9.98G [04:29<09:16, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  33%|███▎      | 3.29G/9.98G [04:30<09:14, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  33%|███▎      | 3.30G/9.98G [04:31<09:10, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  33%|███▎      | 3.31G/9.98G [04:32<09:07, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  33%|███▎      | 3.32G/9.98G [04:33<09:06, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  33%|███▎      | 3.33G/9.98G [04:33<09:04, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  34%|███▎      | 3.34G/9.98G [04:34<09:03, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  34%|███▎      | 3.36G/9.98G [04:35<09:00, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  34%|███▎      | 3.37G/9.98G [04:36<08:59, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  34%|███▍      | 3.38G/9.98G [04:37<09:00, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  34%|███▍      | 3.39G/9.98G [04:38<08:59, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  34%|███▍      | 3.40G/9.98G [04:39<09:11, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  34%|███▍      | 3.41G/9.98G [04:40<09:06, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  34%|███▍      | 3.42G/9.98G [04:40<09:03, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  34%|███▍      | 3.43G/9.98G [04:41<09:00, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  34%|███▍      | 3.44G/9.98G [04:42<09:00, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  35%|███▍      | 3.45G/9.98G [04:43<08:56, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  35%|███▍      | 3.46G/9.98G [04:44<08:55, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  35%|███▍      | 3.47G/9.98G [04:45<08:54, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  35%|███▍      | 3.48G/9.98G [04:46<08:51, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  35%|███▍      | 3.49G/9.98G [04:46<08:51, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  35%|███▌      | 3.50G/9.98G [04:47<08:49, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  35%|███▌      | 3.51G/9.98G [04:48<08:47, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  35%|███▌      | 3.52G/9.98G [04:49<09:01, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  35%|███▌      | 3.53G/9.98G [04:50<09:00, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  36%|███▌      | 3.54G/9.98G [04:51<08:53, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  36%|███▌      | 3.55G/9.98G [04:52<08:50, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  36%|███▌      | 3.57G/9.98G [04:52<08:48, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  36%|███▌      | 3.58G/9.98G [04:53<08:46, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  36%|███▌      | 3.59G/9.98G [04:54<08:44, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  36%|███▌      | 3.60G/9.98G [04:55<08:43, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  36%|███▌      | 3.61G/9.98G [04:56<08:41, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  36%|███▋      | 3.62G/9.98G [04:57<08:40, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  36%|███▋      | 3.63G/9.98G [04:58<08:38, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  36%|███▋      | 3.64G/9.98G [04:58<08:38, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  37%|███▋      | 3.65G/9.98G [04:59<08:49, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  37%|███▋      | 3.66G/9.98G [05:00<08:46, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  37%|███▋      | 3.67G/9.98G [05:01<08:43, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  37%|███▋      | 3.68G/9.98G [05:02<08:41, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  37%|███▋      | 3.69G/9.98G [05:03<08:36, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  37%|███▋      | 3.70G/9.98G [05:04<08:35, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  37%|███▋      | 3.71G/9.98G [05:05<08:33, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  37%|███▋      | 3.72G/9.98G [05:05<08:33, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  37%|███▋      | 3.73G/9.98G [05:06<08:31, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  38%|███▊      | 3.74G/9.98G [05:07<08:29, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  38%|███▊      | 3.75G/9.98G [05:08<08:30, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  38%|███▊      | 3.76G/9.98G [05:09<08:30, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  38%|███▊      | 3.77G/9.98G [05:10<08:37, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  38%|███▊      | 3.79G/9.98G [05:11<08:33, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  38%|███▊      | 3.80G/9.98G [05:11<08:31, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  38%|███▊      | 3.81G/9.98G [05:12<08:28, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  38%|███▊      | 3.82G/9.98G [05:13<08:26, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  38%|███▊      | 3.83G/9.98G [05:14<09:12, 11.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  38%|███▊      | 3.84G/9.98G [05:16<10:03, 10.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  39%|███▊      | 3.85G/9.98G [05:17<11:13, 9.10MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  39%|███▊      | 3.86G/9.98G [05:18<11:38, 8.76MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  39%|███▉      | 3.87G/9.98G [05:20<12:56, 7.87MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  39%|███▉      | 3.88G/9.98G [05:22<13:52, 7.32MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  39%|███▉      | 3.89G/9.98G [05:23<13:50, 7.33MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  39%|███▉      | 3.90G/9.98G [05:24<13:21, 7.58MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  39%|███▉      | 3.91G/9.98G [05:26<13:30, 7.49MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  39%|███▉      | 3.92G/9.98G [05:27<13:00, 7.76MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  39%|███▉      | 3.93G/9.98G [05:28<13:14, 7.61MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  40%|███▉      | 3.94G/9.98G [05:30<12:48, 7.86MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  40%|███▉      | 3.95G/9.98G [05:31<12:36, 7.96MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  40%|███▉      | 3.96G/9.98G [05:32<12:48, 7.82MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  40%|███▉      | 3.97G/9.98G [05:34<12:28, 8.02MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  40%|███▉      | 3.98G/9.98G [05:35<12:14, 8.16MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  40%|████      | 4.00G/9.98G [05:36<12:01, 8.30MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  40%|████      | 4.01G/9.98G [05:37<11:47, 8.44MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  40%|████      | 4.02G/9.98G [05:38<11:05, 8.96MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  40%|████      | 4.03G/9.98G [05:39<10:39, 9.31MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  40%|████      | 4.04G/9.98G [05:40<10:18, 9.61MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  41%|████      | 4.05G/9.98G [05:41<10:23, 9.51MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  41%|████      | 4.06G/9.98G [05:42<10:02, 9.83MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  41%|████      | 4.07G/9.98G [05:44<10:18, 9.56MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  41%|████      | 4.08G/9.98G [05:44<09:57, 9.88MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  41%|████      | 4.09G/9.98G [05:45<09:14, 10.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  41%|████      | 4.10G/9.98G [05:46<09:10, 10.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  41%|████      | 4.11G/9.98G [05:47<08:55, 10.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  41%|████▏     | 4.12G/9.98G [05:48<08:34, 11.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  41%|████▏     | 4.13G/9.98G [05:49<08:34, 11.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  42%|████▏     | 4.14G/9.98G [05:50<08:50, 11.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  42%|████▏     | 4.15G/9.98G [05:51<08:33, 11.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  42%|████▏     | 4.16G/9.98G [05:52<08:24, 11.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  42%|████▏     | 4.17G/9.98G [05:53<08:14, 11.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  42%|████▏     | 4.18G/9.98G [05:53<08:07, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  42%|████▏     | 4.19G/9.98G [05:54<08:03, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  42%|████▏     | 4.20G/9.98G [05:55<08:19, 11.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  42%|████▏     | 4.22G/9.98G [05:56<08:57, 10.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  42%|████▏     | 4.23G/9.98G [05:57<09:06, 10.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  42%|████▏     | 4.24G/9.98G [05:58<08:45, 10.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  43%|████▎     | 4.25G/9.98G [05:59<08:33, 11.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  43%|████▎     | 4.26G/9.98G [06:00<08:40, 11.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  43%|████▎     | 4.27G/9.98G [06:01<08:25, 11.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  43%|████▎     | 4.28G/9.98G [06:02<08:08, 11.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  43%|████▎     | 4.29G/9.98G [06:03<08:09, 11.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  43%|████▎     | 4.30G/9.98G [06:04<08:04, 11.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  43%|████▎     | 4.31G/9.98G [06:05<07:55, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  43%|████▎     | 4.32G/9.98G [06:05<07:36, 12.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  43%|████▎     | 4.33G/9.98G [06:06<08:26, 11.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  44%|████▎     | 4.34G/9.98G [06:07<08:33, 11.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  44%|████▎     | 4.35G/9.98G [06:08<08:40, 10.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  44%|████▎     | 4.36G/9.98G [06:09<08:41, 10.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  44%|████▍     | 4.37G/9.98G [06:10<08:35, 10.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  44%|████▍     | 4.38G/9.98G [06:11<08:39, 10.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  44%|████▍     | 4.39G/9.98G [06:12<08:26, 11.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  44%|████▍     | 4.40G/9.98G [06:13<08:11, 11.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  44%|████▍     | 4.41G/9.98G [06:14<08:05, 11.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  44%|████▍     | 4.42G/9.98G [06:15<07:38, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  44%|████▍     | 4.44G/9.98G [06:16<07:58, 11.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  45%|████▍     | 4.45G/9.98G [06:17<07:41, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  45%|████▍     | 4.46G/9.98G [06:17<07:40, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  45%|████▍     | 4.47G/9.98G [06:18<07:53, 11.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  45%|████▍     | 4.48G/9.98G [06:19<07:46, 11.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  45%|████▍     | 4.49G/9.98G [06:20<07:35, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  45%|████▌     | 4.50G/9.98G [06:21<07:31, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  45%|████▌     | 4.51G/9.98G [06:22<08:04, 11.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  45%|████▌     | 4.52G/9.98G [06:23<07:52, 11.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  45%|████▌     | 4.53G/9.98G [06:24<07:43, 11.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  46%|████▌     | 4.54G/9.98G [06:25<07:38, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  46%|████▌     | 4.55G/9.98G [06:25<07:32, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  46%|████▌     | 4.56G/9.98G [06:26<07:29, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  46%|████▌     | 4.57G/9.98G [06:27<07:27, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  46%|████▌     | 4.58G/9.98G [06:28<07:25, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  46%|████▌     | 4.59G/9.98G [06:29<07:22, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  46%|████▌     | 4.60G/9.98G [06:30<07:21, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  46%|████▌     | 4.61G/9.98G [06:31<07:20, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  46%|████▋     | 4.62G/9.98G [06:31<07:18, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  46%|████▋     | 4.63G/9.98G [06:33<08:00, 11.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  47%|████▋     | 4.65G/9.98G [06:33<07:45, 11.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  47%|████▋     | 4.66G/9.98G [06:34<07:35, 11.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  47%|████▋     | 4.67G/9.98G [06:35<07:29, 11.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  47%|████▋     | 4.68G/9.98G [06:36<07:24, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  47%|████▋     | 4.69G/9.98G [06:37<07:20, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  47%|████▋     | 4.70G/9.98G [06:38<07:18, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  47%|████▋     | 4.71G/9.98G [06:39<07:14, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  47%|████▋     | 4.72G/9.98G [06:39<07:13, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  47%|████▋     | 4.73G/9.98G [06:40<07:11, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  48%|████▊     | 4.74G/9.98G [06:41<07:09, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  48%|████▊     | 4.75G/9.98G [06:42<07:35, 11.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  48%|████▊     | 4.76G/9.98G [06:43<07:12, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  48%|████▊     | 4.77G/9.98G [06:44<07:09, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  48%|████▊     | 4.78G/9.98G [06:45<07:06, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  48%|████▊     | 4.79G/9.98G [06:46<07:05, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  48%|████▊     | 4.80G/9.98G [06:46<07:04, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  48%|████▊     | 4.81G/9.98G [06:47<07:02, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  48%|████▊     | 4.82G/9.98G [06:48<07:01, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  48%|████▊     | 4.83G/9.98G [06:49<07:00, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  49%|████▊     | 4.84G/9.98G [06:50<06:58, 12.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  49%|████▊     | 4.85G/9.98G [06:51<06:58, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  49%|████▉     | 4.87G/9.98G [06:52<06:58, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  49%|████▉     | 4.88G/9.98G [06:53<07:10, 11.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  49%|████▉     | 4.89G/9.98G [06:53<07:03, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  49%|████▉     | 4.90G/9.98G [06:54<07:00, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  49%|████▉     | 4.91G/9.98G [06:55<06:57, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  49%|████▉     | 4.92G/9.98G [06:56<06:57, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  49%|████▉     | 4.93G/9.98G [06:57<06:54, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  50%|████▉     | 4.94G/9.98G [06:58<06:53, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  50%|████▉     | 4.95G/9.98G [06:59<06:53, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  50%|████▉     | 4.96G/9.98G [06:59<06:51, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  50%|████▉     | 4.97G/9.98G [07:00<06:50, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  50%|████▉     | 4.98G/9.98G [07:01<06:48, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  50%|█████     | 4.99G/9.98G [07:02<06:48, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  50%|█████     | 5.00G/9.98G [07:03<07:00, 11.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  50%|█████     | 5.01G/9.98G [07:04<06:52, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  50%|█████     | 5.02G/9.98G [07:05<06:49, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  50%|█████     | 5.03G/9.98G [07:05<06:47, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  51%|█████     | 5.04G/9.98G [07:06<06:46, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  51%|█████     | 5.05G/9.98G [07:07<06:44, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  51%|█████     | 5.06G/9.98G [07:08<06:43, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  51%|█████     | 5.08G/9.98G [07:09<06:41, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  51%|█████     | 5.09G/9.98G [07:10<06:39, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  51%|█████     | 5.10G/9.98G [07:11<06:39, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  51%|█████     | 5.11G/9.98G [07:11<06:38, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  51%|█████▏    | 5.12G/9.98G [07:12<06:36, 12.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  51%|█████▏    | 5.13G/9.98G [07:13<06:45, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  52%|█████▏    | 5.14G/9.98G [07:14<06:42, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  52%|█████▏    | 5.15G/9.98G [07:15<06:40, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  52%|█████▏    | 5.16G/9.98G [07:16<06:36, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  52%|█████▏    | 5.17G/9.98G [07:17<06:35, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  52%|█████▏    | 5.18G/9.98G [07:18<06:33, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  52%|█████▏    | 5.19G/9.98G [07:18<06:33, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  52%|█████▏    | 5.20G/9.98G [07:19<06:31, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  52%|█████▏    | 5.21G/9.98G [07:20<06:29, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  52%|█████▏    | 5.22G/9.98G [07:21<06:29, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  52%|█████▏    | 5.23G/9.98G [07:22<06:27, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  53%|█████▎    | 5.24G/9.98G [07:23<06:26, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  53%|█████▎    | 5.25G/9.98G [07:24<06:35, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  53%|█████▎    | 5.26G/9.98G [07:24<06:31, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  53%|█████▎    | 5.27G/9.98G [07:25<06:29, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  53%|█████▎    | 5.28G/9.98G [07:26<06:27, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  53%|█████▎    | 5.30G/9.98G [07:27<06:27, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  53%|█████▎    | 5.31G/9.98G [07:28<06:23, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  53%|█████▎    | 5.32G/9.98G [07:29<06:22, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  53%|█████▎    | 5.33G/9.98G [07:30<06:21, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  53%|█████▎    | 5.34G/9.98G [07:30<06:20, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  54%|█████▎    | 5.35G/9.98G [07:31<06:18, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  54%|█████▎    | 5.36G/9.98G [07:32<06:18, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  54%|█████▍    | 5.37G/9.98G [07:33<06:17, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  54%|█████▍    | 5.38G/9.98G [07:34<06:25, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  54%|█████▍    | 5.39G/9.98G [07:35<06:21, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  54%|█████▍    | 5.40G/9.98G [07:36<06:17, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  54%|█████▍    | 5.41G/9.98G [07:37<06:16, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  54%|█████▍    | 5.42G/9.98G [07:37<06:14, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  54%|█████▍    | 5.43G/9.98G [07:38<06:12, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  55%|█████▍    | 5.44G/9.98G [07:39<06:11, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  55%|█████▍    | 5.45G/9.98G [07:40<06:10, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  55%|█████▍    | 5.46G/9.98G [07:41<06:09, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  55%|█████▍    | 5.47G/9.98G [07:42<06:09, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  55%|█████▍    | 5.48G/9.98G [07:43<06:07, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  55%|█████▌    | 5.49G/9.98G [07:43<06:06, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  55%|█████▌    | 5.51G/9.98G [07:44<06:14, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  55%|█████▌    | 5.52G/9.98G [07:45<06:10, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  55%|█████▌    | 5.53G/9.98G [07:46<06:08, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  55%|█████▌    | 5.54G/9.98G [07:47<06:06, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  56%|█████▌    | 5.55G/9.98G [07:48<06:04, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  56%|█████▌    | 5.56G/9.98G [07:49<06:02, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  56%|█████▌    | 5.57G/9.98G [07:49<06:01, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  56%|█████▌    | 5.58G/9.98G [07:50<06:00, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  56%|█████▌    | 5.59G/9.98G [07:51<05:58, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  56%|█████▌    | 5.60G/9.98G [07:52<05:57, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  56%|█████▌    | 5.61G/9.98G [07:53<05:56, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  56%|█████▋    | 5.62G/9.98G [07:54<05:56, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  56%|█████▋    | 5.63G/9.98G [07:55<06:03, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  57%|█████▋    | 5.64G/9.98G [07:56<06:00, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  57%|█████▋    | 5.65G/9.98G [07:56<05:57, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  57%|█████▋    | 5.66G/9.98G [07:57<05:55, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  57%|█████▋    | 5.67G/9.98G [07:58<05:53, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  57%|█████▋    | 5.68G/9.98G [07:59<05:52, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  57%|█████▋    | 5.69G/9.98G [08:00<05:51, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  57%|█████▋    | 5.70G/9.98G [08:01<05:49, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  57%|█████▋    | 5.71G/9.98G [08:02<05:49, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  57%|█████▋    | 5.73G/9.98G [08:02<05:48, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  57%|█████▋    | 5.74G/9.98G [08:03<05:47, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  58%|█████▊    | 5.75G/9.98G [08:04<06:05, 11.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  58%|█████▊    | 5.76G/9.98G [08:05<05:48, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  58%|█████▊    | 5.77G/9.98G [08:06<05:47, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  58%|█████▊    | 5.78G/9.98G [08:07<05:44, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  58%|█████▊    | 5.79G/9.98G [08:08<05:43, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  58%|█████▊    | 5.80G/9.98G [08:08<05:42, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  58%|█████▊    | 5.81G/9.98G [08:09<05:41, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  58%|█████▊    | 5.82G/9.98G [08:10<05:39, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  58%|█████▊    | 5.83G/9.98G [08:11<05:39, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  59%|█████▊    | 5.84G/9.98G [08:12<05:37, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  59%|█████▊    | 5.85G/9.98G [08:13<05:37, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  59%|█████▉    | 5.86G/9.98G [08:14<05:35, 12.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  59%|█████▉    | 5.87G/9.98G [08:15<05:54, 11.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  59%|█████▉    | 5.88G/9.98G [08:15<05:35, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  59%|█████▉    | 5.89G/9.98G [08:16<05:35, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  59%|█████▉    | 5.90G/9.98G [08:17<05:34, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  59%|█████▉    | 5.91G/9.98G [08:18<05:33, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  59%|█████▉    | 5.92G/9.98G [08:19<05:31, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  59%|█████▉    | 5.93G/9.98G [08:20<05:30, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  60%|█████▉    | 5.95G/9.98G [08:21<05:30, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  60%|█████▉    | 5.96G/9.98G [08:21<05:29, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  60%|█████▉    | 5.97G/9.98G [08:22<05:27, 12.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  60%|█████▉    | 5.98G/9.98G [08:23<05:28, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  60%|██████    | 5.99G/9.98G [08:24<05:25, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  60%|██████    | 6.00G/9.98G [08:25<05:44, 11.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  60%|██████    | 6.01G/9.98G [08:26<05:26, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  60%|██████    | 6.02G/9.98G [08:27<05:25, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  60%|██████    | 6.03G/9.98G [08:27<05:23, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  61%|██████    | 6.04G/9.98G [08:28<05:22, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  61%|██████    | 6.05G/9.98G [08:29<05:21, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  61%|██████    | 6.06G/9.98G [08:30<05:21, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  61%|██████    | 6.07G/9.98G [08:31<05:20, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  61%|██████    | 6.08G/9.98G [08:32<05:18, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  61%|██████    | 6.09G/9.98G [08:33<05:19, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  61%|██████    | 6.10G/9.98G [08:33<05:18, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  61%|██████▏   | 6.11G/9.98G [08:34<05:16, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  61%|██████▏   | 6.12G/9.98G [08:35<05:24, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  61%|██████▏   | 6.13G/9.98G [08:36<05:19, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  62%|██████▏   | 6.14G/9.98G [08:37<05:17, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  62%|██████▏   | 6.16G/9.98G [08:38<05:15, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  62%|██████▏   | 6.17G/9.98G [08:39<05:13, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  62%|██████▏   | 6.18G/9.98G [08:40<05:12, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  62%|██████▏   | 6.19G/9.98G [08:40<05:10, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  62%|██████▏   | 6.20G/9.98G [08:41<05:09, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  62%|██████▏   | 6.21G/9.98G [08:42<05:08, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  62%|██████▏   | 6.22G/9.98G [08:43<05:07, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  62%|██████▏   | 6.23G/9.98G [08:44<05:06, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  63%|██████▎   | 6.24G/9.98G [08:45<05:05, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  63%|██████▎   | 6.25G/9.98G [08:46<05:12, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  63%|██████▎   | 6.26G/9.98G [08:46<05:09, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  63%|██████▎   | 6.27G/9.98G [08:47<05:07, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  63%|██████▎   | 6.28G/9.98G [08:48<05:05, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  63%|██████▎   | 6.29G/9.98G [08:49<05:03, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  63%|██████▎   | 6.30G/9.98G [08:50<05:02, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  63%|██████▎   | 6.31G/9.98G [08:51<05:00, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  63%|██████▎   | 6.32G/9.98G [08:52<04:59, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  63%|██████▎   | 6.33G/9.98G [08:52<04:58, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  64%|██████▎   | 6.34G/9.98G [08:53<04:57, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  64%|██████▎   | 6.35G/9.98G [08:54<04:56, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  64%|██████▍   | 6.36G/9.98G [08:55<04:55, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  64%|██████▍   | 6.38G/9.98G [08:56<05:04, 11.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  64%|██████▍   | 6.39G/9.98G [08:57<05:02, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  64%|██████▍   | 6.40G/9.98G [08:58<04:58, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  64%|██████▍   | 6.41G/9.98G [08:59<04:55, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  64%|██████▍   | 6.42G/9.98G [08:59<04:54, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  64%|██████▍   | 6.43G/9.98G [09:00<04:52, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  65%|██████▍   | 6.44G/9.98G [09:01<04:50, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  65%|██████▍   | 6.45G/9.98G [09:02<04:49, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  65%|██████▍   | 6.46G/9.98G [09:03<04:48, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  65%|██████▍   | 6.47G/9.98G [09:04<04:47, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  65%|██████▍   | 6.48G/9.98G [09:05<04:46, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  65%|██████▌   | 6.49G/9.98G [09:05<04:46, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  65%|██████▌   | 6.50G/9.98G [09:06<04:52, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  65%|██████▌   | 6.51G/9.98G [09:07<04:49, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  65%|██████▌   | 6.52G/9.98G [09:08<04:47, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  65%|██████▌   | 6.53G/9.98G [09:09<04:44, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  66%|██████▌   | 6.54G/9.98G [09:10<04:43, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  66%|██████▌   | 6.55G/9.98G [09:11<04:41, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  66%|██████▌   | 6.56G/9.98G [09:12<04:40, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  66%|██████▌   | 6.57G/9.98G [09:12<04:39, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  66%|██████▌   | 6.59G/9.98G [09:13<04:39, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  66%|██████▌   | 6.60G/9.98G [09:14<04:37, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  66%|██████▌   | 6.61G/9.98G [09:15<04:36, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  66%|██████▋   | 6.62G/9.98G [09:16<04:34, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  66%|██████▋   | 6.63G/9.98G [09:17<04:40, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  67%|██████▋   | 6.64G/9.98G [09:18<04:38, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  67%|██████▋   | 6.65G/9.98G [09:18<04:36, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  67%|██████▋   | 6.66G/9.98G [09:19<04:33, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  67%|██████▋   | 6.67G/9.98G [09:20<04:32, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  67%|██████▋   | 6.68G/9.98G [09:21<04:31, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  67%|██████▋   | 6.69G/9.98G [09:22<04:29, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  67%|██████▋   | 6.70G/9.98G [09:23<04:28, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  67%|██████▋   | 6.71G/9.98G [09:24<04:27, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  67%|██████▋   | 6.72G/9.98G [09:24<04:26, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  67%|██████▋   | 6.73G/9.98G [09:25<04:26, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  68%|██████▊   | 6.74G/9.98G [09:26<04:42, 11.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  68%|██████▊   | 6.75G/9.98G [09:27<04:26, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  68%|██████▊   | 6.76G/9.98G [09:28<04:25, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  68%|██████▊   | 6.77G/9.98G [09:29<04:23, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  68%|██████▊   | 6.78G/9.98G [09:30<04:22, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  68%|██████▊   | 6.79G/9.98G [09:31<04:20, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  68%|██████▊   | 6.81G/9.98G [09:31<04:19, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  68%|██████▊   | 6.82G/9.98G [09:32<04:19, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  68%|██████▊   | 6.83G/9.98G [09:33<04:18, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  69%|██████▊   | 6.84G/9.98G [09:34<04:17, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  69%|██████▊   | 6.85G/9.98G [09:35<04:16, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  69%|██████▊   | 6.86G/9.98G [09:36<04:15, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  69%|██████▉   | 6.87G/9.98G [09:37<04:21, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  69%|██████▉   | 6.88G/9.98G [09:38<04:17, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  69%|██████▉   | 6.89G/9.98G [09:38<04:15, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  69%|██████▉   | 6.90G/9.98G [09:39<04:13, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  69%|██████▉   | 6.91G/9.98G [09:40<04:12, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  69%|██████▉   | 6.92G/9.98G [09:41<04:11, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  69%|██████▉   | 6.93G/9.98G [09:42<04:10, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  70%|██████▉   | 6.94G/9.98G [09:43<04:10, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  70%|██████▉   | 6.95G/9.98G [09:44<04:09, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  70%|██████▉   | 6.96G/9.98G [09:44<04:07, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  70%|██████▉   | 6.97G/9.98G [09:45<04:06, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  70%|██████▉   | 6.98G/9.98G [09:46<04:05, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  70%|███████   | 6.99G/9.98G [09:47<04:10, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  70%|███████   | 7.00G/9.98G [09:48<04:07, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  70%|███████   | 7.01G/9.98G [09:49<04:05, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  70%|███████   | 7.03G/9.98G [09:50<04:03, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  71%|███████   | 7.04G/9.98G [09:50<04:02, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  71%|███████   | 7.05G/9.98G [09:51<04:00, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  71%|███████   | 7.06G/9.98G [09:52<04:00, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  71%|███████   | 7.07G/9.98G [09:53<03:58, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  71%|███████   | 7.08G/9.98G [09:54<03:57, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  71%|███████   | 7.09G/9.98G [09:55<03:56, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  71%|███████   | 7.10G/9.98G [09:56<03:55, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  71%|███████▏  | 7.11G/9.98G [09:57<03:55, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  71%|███████▏  | 7.12G/9.98G [09:57<04:00, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  71%|███████▏  | 7.13G/9.98G [09:58<03:57, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  72%|███████▏  | 7.14G/9.98G [09:59<03:54, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  72%|███████▏  | 7.15G/9.98G [10:00<03:53, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  72%|███████▏  | 7.16G/9.98G [10:01<03:52, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  72%|███████▏  | 7.17G/9.98G [10:02<03:50, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  72%|███████▏  | 7.18G/9.98G [10:03<03:49, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  72%|███████▏  | 7.19G/9.98G [10:03<03:48, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  72%|███████▏  | 7.20G/9.98G [10:04<03:47, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  72%|███████▏  | 7.21G/9.98G [10:05<03:46, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  72%|███████▏  | 7.22G/9.98G [10:06<03:46, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  73%|███████▎  | 7.24G/9.98G [10:07<03:45, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  73%|███████▎  | 7.25G/9.98G [10:08<03:48, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  73%|███████▎  | 7.26G/9.98G [10:09<03:46, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  73%|███████▎  | 7.27G/9.98G [10:10<03:44, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  73%|███████▎  | 7.28G/9.98G [10:10<03:43, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  73%|███████▎  | 7.29G/9.98G [10:11<03:41, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  73%|███████▎  | 7.30G/9.98G [10:12<03:40, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  73%|███████▎  | 7.31G/9.98G [10:13<03:39, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  73%|███████▎  | 7.32G/9.98G [10:14<03:38, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  73%|███████▎  | 7.33G/9.98G [10:15<03:37, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  74%|███████▎  | 7.34G/9.98G [10:16<03:36, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  74%|███████▎  | 7.35G/9.98G [10:16<03:35, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  74%|███████▍  | 7.36G/9.98G [10:17<03:34, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  74%|███████▍  | 7.37G/9.98G [10:18<03:39, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  74%|███████▍  | 7.38G/9.98G [10:19<03:36, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  74%|███████▍  | 7.39G/9.98G [10:20<03:34, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  74%|███████▍  | 7.40G/9.98G [10:21<03:32, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  74%|███████▍  | 7.41G/9.98G [10:22<03:31, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  74%|███████▍  | 7.42G/9.98G [10:22<03:29, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  75%|███████▍  | 7.43G/9.98G [10:23<03:28, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  75%|███████▍  | 7.44G/9.98G [10:24<03:27, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  75%|███████▍  | 7.46G/9.98G [10:25<03:26, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  75%|███████▍  | 7.47G/9.98G [10:26<03:25, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  75%|███████▍  | 7.48G/9.98G [10:27<03:24, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  75%|███████▌  | 7.49G/9.98G [10:28<03:36, 11.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  75%|███████▌  | 7.50G/9.98G [10:29<03:23, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  75%|███████▌  | 7.51G/9.98G [10:29<03:22, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  75%|███████▌  | 7.52G/9.98G [10:30<03:21, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  75%|███████▌  | 7.53G/9.98G [10:31<03:20, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  76%|███████▌  | 7.54G/9.98G [10:32<03:19, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  76%|███████▌  | 7.55G/9.98G [10:33<03:18, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  76%|███████▌  | 7.56G/9.98G [10:34<03:17, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  76%|███████▌  | 7.57G/9.98G [10:35<03:16, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  76%|███████▌  | 7.58G/9.98G [10:35<03:19, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  76%|███████▌  | 7.59G/9.98G [10:36<03:17, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  76%|███████▌  | 7.60G/9.98G [10:37<03:15, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  76%|███████▋  | 7.61G/9.98G [10:38<03:25, 11.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  76%|███████▋  | 7.62G/9.98G [10:39<03:22, 11.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  77%|███████▋  | 7.63G/9.98G [10:40<03:17, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  77%|███████▋  | 7.64G/9.98G [10:41<03:20, 11.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  77%|███████▋  | 7.65G/9.98G [10:42<03:11, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  77%|███████▋  | 7.67G/9.98G [10:42<03:10, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  77%|███████▋  | 7.68G/9.98G [10:43<03:12, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  77%|███████▋  | 7.69G/9.98G [10:44<03:06, 12.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  77%|███████▋  | 7.70G/9.98G [10:45<03:05, 12.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  77%|███████▋  | 7.71G/9.98G [10:46<03:05, 12.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  77%|███████▋  | 7.72G/9.98G [10:47<03:04, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  77%|███████▋  | 7.73G/9.98G [10:48<03:04, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  78%|███████▊  | 7.74G/9.98G [10:49<03:07, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  78%|███████▊  | 7.75G/9.98G [10:49<03:05, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  78%|███████▊  | 7.76G/9.98G [10:50<03:03, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  78%|███████▊  | 7.77G/9.98G [10:51<03:02, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  78%|███████▊  | 7.78G/9.98G [10:52<03:00, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  78%|███████▊  | 7.79G/9.98G [10:53<02:59, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  78%|███████▊  | 7.80G/9.98G [10:54<02:58, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  78%|███████▊  | 7.81G/9.98G [10:55<02:57, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  78%|███████▊  | 7.82G/9.98G [10:55<02:56, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  79%|███████▊  | 7.83G/9.98G [10:56<02:55, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  79%|███████▊  | 7.84G/9.98G [10:57<02:54, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  79%|███████▊  | 7.85G/9.98G [10:58<02:54, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  79%|███████▉  | 7.86G/9.98G [10:59<02:57, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  79%|███████▉  | 7.87G/9.98G [11:00<02:55, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  79%|███████▉  | 7.89G/9.98G [11:01<02:53, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  79%|███████▉  | 7.90G/9.98G [11:02<02:51, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  79%|███████▉  | 7.91G/9.98G [11:02<02:50, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  79%|███████▉  | 7.92G/9.98G [11:03<02:49, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  79%|███████▉  | 7.93G/9.98G [11:04<02:48, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  80%|███████▉  | 7.94G/9.98G [11:05<02:47, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  80%|███████▉  | 7.95G/9.98G [11:06<02:46, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  80%|███████▉  | 7.96G/9.98G [11:07<02:45, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  80%|███████▉  | 7.97G/9.98G [11:08<02:44, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  80%|███████▉  | 7.98G/9.98G [11:08<02:43, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  80%|████████  | 7.99G/9.98G [11:09<02:46, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  80%|████████  | 8.00G/9.98G [11:10<02:44, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  80%|████████  | 8.01G/9.98G [11:11<02:42, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  80%|████████  | 8.02G/9.98G [11:12<02:41, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  81%|████████  | 8.03G/9.98G [11:13<02:40, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  81%|████████  | 8.04G/9.98G [11:14<02:38, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  81%|████████  | 8.05G/9.98G [11:14<02:37, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  81%|████████  | 8.06G/9.98G [11:15<02:36, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  81%|████████  | 8.07G/9.98G [11:16<02:35, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  81%|████████  | 8.08G/9.98G [11:17<02:34, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  81%|████████  | 8.10G/9.98G [11:18<02:33, 12.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  81%|████████  | 8.11G/9.98G [11:19<02:32, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  81%|████████▏ | 8.12G/9.98G [11:20<02:38, 11.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  81%|████████▏ | 8.13G/9.98G [11:21<02:35, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  82%|████████▏ | 8.14G/9.98G [11:21<02:33, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  82%|████████▏ | 8.15G/9.98G [11:22<02:31, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  82%|████████▏ | 8.16G/9.98G [11:23<02:29, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  82%|████████▏ | 8.17G/9.98G [11:24<02:28, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  82%|████████▏ | 8.18G/9.98G [11:25<02:27, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  82%|████████▏ | 8.19G/9.98G [11:26<02:26, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  82%|████████▏ | 8.20G/9.98G [11:27<02:26, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  82%|████████▏ | 8.21G/9.98G [11:27<02:25, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  82%|████████▏ | 8.22G/9.98G [11:28<02:24, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  83%|████████▎ | 8.23G/9.98G [11:29<02:29, 11.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  83%|████████▎ | 8.24G/9.98G [11:30<02:23, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  83%|████████▎ | 8.25G/9.98G [11:31<02:22, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  83%|████████▎ | 8.26G/9.98G [11:32<02:20, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  83%|████████▎ | 8.27G/9.98G [11:33<02:20, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  83%|████████▎ | 8.28G/9.98G [11:34<02:19, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  83%|████████▎ | 8.29G/9.98G [11:34<02:18, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  83%|████████▎ | 8.30G/9.98G [11:35<02:17, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  83%|████████▎ | 8.32G/9.98G [11:36<02:16, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  83%|████████▎ | 8.33G/9.98G [11:37<02:15, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  84%|████████▎ | 8.34G/9.98G [11:38<02:14, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  84%|████████▎ | 8.35G/9.98G [11:39<02:13, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  84%|████████▍ | 8.36G/9.98G [11:40<02:15, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  84%|████████▍ | 8.37G/9.98G [11:40<02:14, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  84%|████████▍ | 8.38G/9.98G [11:41<02:12, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  84%|████████▍ | 8.39G/9.98G [11:42<02:11, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  84%|████████▍ | 8.40G/9.98G [11:43<02:09, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  84%|████████▍ | 8.41G/9.98G [11:44<02:08, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  84%|████████▍ | 8.42G/9.98G [11:45<02:08, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  85%|████████▍ | 8.43G/9.98G [11:46<02:07, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  85%|████████▍ | 8.44G/9.98G [11:46<02:06, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  85%|████████▍ | 8.45G/9.98G [11:47<02:05, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  85%|████████▍ | 8.46G/9.98G [11:48<02:04, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  85%|████████▍ | 8.47G/9.98G [11:49<02:03, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  85%|████████▌ | 8.48G/9.98G [11:50<02:05, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  85%|████████▌ | 8.49G/9.98G [11:51<02:06, 11.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  85%|████████▌ | 8.50G/9.98G [11:52<02:16, 10.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  85%|████████▌ | 8.51G/9.98G [11:53<02:15, 10.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  85%|████████▌ | 8.52G/9.98G [11:54<02:17, 10.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  86%|████████▌ | 8.54G/9.98G [11:55<02:23, 10.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  86%|████████▌ | 8.55G/9.98G [11:56<02:20, 10.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  86%|████████▌ | 8.56G/9.98G [11:57<02:16, 10.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  86%|████████▌ | 8.57G/9.98G [11:58<02:18, 10.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  86%|████████▌ | 8.58G/9.98G [11:59<02:12, 10.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  86%|████████▌ | 8.59G/9.98G [12:00<02:14, 10.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  86%|████████▌ | 8.60G/9.98G [12:01<02:08, 10.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  86%|████████▋ | 8.61G/9.98G [12:02<02:01, 11.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  86%|████████▋ | 8.62G/9.98G [12:03<01:59, 11.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  86%|████████▋ | 8.63G/9.98G [12:04<01:54, 11.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  87%|████████▋ | 8.64G/9.98G [12:05<01:52, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  87%|████████▋ | 8.65G/9.98G [12:05<01:50, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  87%|████████▋ | 8.66G/9.98G [12:06<01:50, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  87%|████████▋ | 8.67G/9.98G [12:07<01:52, 11.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  87%|████████▋ | 8.68G/9.98G [12:08<02:03, 10.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  87%|████████▋ | 8.69G/9.98G [12:10<02:08, 9.98MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  87%|████████▋ | 8.70G/9.98G [12:11<02:10, 9.75MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  87%|████████▋ | 8.71G/9.98G [12:12<02:10, 9.68MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  87%|████████▋ | 8.72G/9.98G [12:13<02:04, 10.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  88%|████████▊ | 8.73G/9.98G [12:14<02:02, 10.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  88%|████████▊ | 8.75G/9.98G [12:15<02:05, 9.79MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  88%|████████▊ | 8.76G/9.98G [12:16<02:01, 10.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  88%|████████▊ | 8.77G/9.98G [12:17<02:00, 10.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  88%|████████▊ | 8.78G/9.98G [12:18<02:03, 9.75MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  88%|████████▊ | 8.79G/9.98G [12:19<01:58, 10.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  88%|████████▊ | 8.80G/9.98G [12:20<01:56, 10.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  88%|████████▊ | 8.81G/9.98G [12:21<01:58, 9.90MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  88%|████████▊ | 8.82G/9.98G [12:22<01:55, 10.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  88%|████████▊ | 8.83G/9.98G [12:23<01:52, 10.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  89%|████████▊ | 8.84G/9.98G [12:24<01:44, 10.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  89%|████████▊ | 8.85G/9.98G [12:25<01:45, 10.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  89%|████████▉ | 8.86G/9.98G [12:26<01:40, 11.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  89%|████████▉ | 8.87G/9.98G [12:27<01:34, 11.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  89%|████████▉ | 8.88G/9.98G [12:28<01:35, 11.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  89%|████████▉ | 8.89G/9.98G [12:29<01:37, 11.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  89%|████████▉ | 8.90G/9.98G [12:30<01:39, 10.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  89%|████████▉ | 8.91G/9.98G [12:31<01:36, 11.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  89%|████████▉ | 8.92G/9.98G [12:31<01:30, 11.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  90%|████████▉ | 8.93G/9.98G [12:32<01:29, 11.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  90%|████████▉ | 8.94G/9.98G [12:33<01:25, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  90%|████████▉ | 8.95G/9.98G [12:34<01:26, 11.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  90%|████████▉ | 8.97G/9.98G [12:35<01:22, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  90%|████████▉ | 8.98G/9.98G [12:36<01:21, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  90%|█████████ | 8.99G/9.98G [12:37<01:20, 12.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  90%|█████████ | 9.00G/9.98G [12:37<01:20, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  90%|█████████ | 9.01G/9.98G [12:38<01:19, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  90%|█████████ | 9.02G/9.98G [12:39<01:18, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  90%|█████████ | 9.03G/9.98G [12:40<01:17, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  91%|█████████ | 9.04G/9.98G [12:41<01:16, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  91%|█████████ | 9.05G/9.98G [12:42<01:18, 11.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  91%|█████████ | 9.06G/9.98G [12:43<01:16, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  91%|█████████ | 9.07G/9.98G [12:44<01:15, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  91%|█████████ | 9.08G/9.98G [12:44<01:14, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  91%|█████████ | 9.09G/9.98G [12:45<01:13, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  91%|█████████ | 9.10G/9.98G [12:46<01:12, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  91%|█████████▏| 9.11G/9.98G [12:47<01:11, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  91%|█████████▏| 9.12G/9.98G [12:48<01:10, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  92%|█████████▏| 9.13G/9.98G [12:49<01:09, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  92%|█████████▏| 9.14G/9.98G [12:50<01:08, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  92%|█████████▏| 9.15G/9.98G [12:50<01:07, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  92%|█████████▏| 9.16G/9.98G [12:51<01:06, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  92%|█████████▏| 9.18G/9.98G [12:52<01:07, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  92%|█████████▏| 9.19G/9.98G [12:53<01:05, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  92%|█████████▏| 9.20G/9.98G [12:54<01:04, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  92%|█████████▏| 9.21G/9.98G [12:55<01:03, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  92%|█████████▏| 9.22G/9.98G [12:56<01:02, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  92%|█████████▏| 9.23G/9.98G [12:57<01:01, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  93%|█████████▎| 9.24G/9.98G [12:57<01:00, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  93%|█████████▎| 9.25G/9.98G [12:58<00:59, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  93%|█████████▎| 9.26G/9.98G [12:59<00:58, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  93%|█████████▎| 9.27G/9.98G [13:00<00:57, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  93%|█████████▎| 9.28G/9.98G [13:01<00:57, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  93%|█████████▎| 9.29G/9.98G [13:02<00:56, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  93%|█████████▎| 9.30G/9.98G [13:03<00:56, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  93%|█████████▎| 9.31G/9.98G [13:03<00:55, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  93%|█████████▎| 9.32G/9.98G [13:04<00:54, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  94%|█████████▎| 9.33G/9.98G [13:05<00:53, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  94%|█████████▎| 9.34G/9.98G [13:06<00:52, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  94%|█████████▍| 9.35G/9.98G [13:07<00:51, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  94%|█████████▍| 9.36G/9.98G [13:08<00:50, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  94%|█████████▍| 9.37G/9.98G [13:09<00:49, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  94%|█████████▍| 9.38G/9.98G [13:09<00:48, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  94%|█████████▍| 9.40G/9.98G [13:10<00:47, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  94%|█████████▍| 9.41G/9.98G [13:11<00:46, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  94%|█████████▍| 9.42G/9.98G [13:12<00:45, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  94%|█████████▍| 9.43G/9.98G [13:13<00:46, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  95%|█████████▍| 9.44G/9.98G [13:14<00:44, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  95%|█████████▍| 9.45G/9.98G [13:15<00:43, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  95%|█████████▍| 9.46G/9.98G [13:16<00:42, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  95%|█████████▍| 9.47G/9.98G [13:16<00:41, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  95%|█████████▌| 9.48G/9.98G [13:17<00:40, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  95%|█████████▌| 9.49G/9.98G [13:18<00:40, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  95%|█████████▌| 9.50G/9.98G [13:19<00:39, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  95%|█████████▌| 9.51G/9.98G [13:20<00:38, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  95%|█████████▌| 9.52G/9.98G [13:21<00:37, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  96%|█████████▌| 9.53G/9.98G [13:22<00:36, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  96%|█████████▌| 9.54G/9.98G [13:22<00:35, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  96%|█████████▌| 9.55G/9.98G [13:23<00:35, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  96%|█████████▌| 9.56G/9.98G [13:24<00:34, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  96%|█████████▌| 9.57G/9.98G [13:25<00:33, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  96%|█████████▌| 9.58G/9.98G [13:26<00:32, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  96%|█████████▌| 9.59G/9.98G [13:27<00:31, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  96%|█████████▋| 9.60G/9.98G [13:28<00:30, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  96%|█████████▋| 9.62G/9.98G [13:28<00:29, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  96%|█████████▋| 9.63G/9.98G [13:29<00:28, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  97%|█████████▋| 9.64G/9.98G [13:30<00:27, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  97%|█████████▋| 9.65G/9.98G [13:31<00:27, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  97%|█████████▋| 9.66G/9.98G [13:32<00:26, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  97%|█████████▋| 9.67G/9.98G [13:33<00:26, 11.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  97%|█████████▋| 9.68G/9.98G [13:34<00:24, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  97%|█████████▋| 9.69G/9.98G [13:35<00:23, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  97%|█████████▋| 9.70G/9.98G [13:35<00:22, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  97%|█████████▋| 9.71G/9.98G [13:36<00:21, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  97%|█████████▋| 9.72G/9.98G [13:37<00:21, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  98%|█████████▊| 9.73G/9.98G [13:38<00:20, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  98%|█████████▊| 9.74G/9.98G [13:39<00:19, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  98%|█████████▊| 9.75G/9.98G [13:40<00:18, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  98%|█████████▊| 9.76G/9.98G [13:41<00:17, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  98%|█████████▊| 9.77G/9.98G [13:41<00:16, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  98%|█████████▊| 9.78G/9.98G [13:42<00:15, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  98%|█████████▊| 9.79G/9.98G [13:43<00:15, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  98%|█████████▊| 9.80G/9.98G [13:44<00:14, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  98%|█████████▊| 9.81G/9.98G [13:45<00:13, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  98%|█████████▊| 9.83G/9.98G [13:46<00:12, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  99%|█████████▊| 9.84G/9.98G [13:47<00:11, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  99%|█████████▊| 9.85G/9.98G [13:48<00:10, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  99%|█████████▉| 9.86G/9.98G [13:48<00:09, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  99%|█████████▉| 9.87G/9.98G [13:49<00:08, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  99%|█████████▉| 9.88G/9.98G [13:50<00:08, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  99%|█████████▉| 9.89G/9.98G [13:51<00:07, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  99%|█████████▉| 9.90G/9.98G [13:52<00:06, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  99%|█████████▉| 9.91G/9.98G [13:53<00:05, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  99%|█████████▉| 9.92G/9.98G [13:54<00:04, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin: 100%|█████████▉| 9.93G/9.98G [13:54<00:03, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin: 100%|█████████▉| 9.94G/9.98G [13:55<00:02, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin: 100%|█████████▉| 9.95G/9.98G [13:56<00:02, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin: 100%|█████████▉| 9.96G/9.98G [13:57<00:01, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin: 100%|█████████▉| 9.97G/9.98G [13:58<00:00, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin: 100%|██████████| 9.98G/9.98G [13:58<00:00, 11.9MB/s]\u001b[A\n",
      "Downloading shards:  50%|█████     | 1/2 [14:00<14:00, 840.26s/it]/opt/conda/lib/python3.8/site-packages/huggingface_hub/file_download.py:983: UserWarning: Not enough free disk space to download the file. The expected file size is: 3500.32 MB. The target location /home/jovyan/.cache/huggingface/hub only has 0.00 MB free disk space.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/huggingface_hub/file_download.py:983: UserWarning: Not enough free disk space to download the file. The expected file size is: 3500.32 MB. The target location /home/jovyan/.cache/huggingface/hub/models--indonlp--cendol-llama2-7b/blobs only has 0.00 MB free disk space.\n",
      "  warnings.warn(\n",
      "\n",
      "pytorch_model-00002-of-00002.bin:   0%|          | 0.00/3.50G [00:00<?, ?B/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   0%|          | 10.5M/3.50G [00:02<12:23, 4.69MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   1%|          | 21.0M/3.50G [00:03<07:42, 7.52MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   1%|          | 31.5M/3.50G [00:03<06:30, 8.88MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   1%|          | 41.9M/3.50G [00:04<05:48, 9.93MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   1%|▏         | 52.4M/3.50G [00:05<05:23, 10.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   2%|▏         | 62.9M/3.50G [00:06<05:08, 11.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   2%|▏         | 73.4M/3.50G [00:07<04:58, 11.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   2%|▏         | 83.9M/3.50G [00:08<04:52, 11.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   3%|▎         | 94.4M/3.50G [00:09<04:48, 11.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   3%|▎         | 105M/3.50G [00:09<04:43, 12.0MB/s] \u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   3%|▎         | 115M/3.50G [00:10<04:41, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   4%|▎         | 126M/3.50G [00:11<04:38, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   4%|▍         | 136M/3.50G [00:12<04:37, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   4%|▍         | 147M/3.50G [00:13<04:35, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   4%|▍         | 157M/3.50G [00:14<04:41, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   5%|▍         | 168M/3.50G [00:15<04:38, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   5%|▌         | 178M/3.50G [00:16<04:35, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   5%|▌         | 189M/3.50G [00:16<04:33, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   6%|▌         | 199M/3.50G [00:17<04:32, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   6%|▌         | 210M/3.50G [00:18<04:31, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   6%|▋         | 220M/3.50G [00:19<04:29, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   7%|▋         | 231M/3.50G [00:20<04:28, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   7%|▋         | 241M/3.50G [00:21<04:27, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   7%|▋         | 252M/3.50G [00:22<04:26, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   7%|▋         | 262M/3.50G [00:22<04:25, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   8%|▊         | 273M/3.50G [00:23<04:24, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   8%|▊         | 283M/3.50G [00:24<04:30, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   8%|▊         | 294M/3.50G [00:25<04:27, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   9%|▊         | 304M/3.50G [00:26<04:24, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   9%|▉         | 315M/3.50G [00:27<04:22, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   9%|▉         | 325M/3.50G [00:28<04:21, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  10%|▉         | 336M/3.50G [00:29<04:20, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  10%|▉         | 346M/3.50G [00:29<04:19, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  10%|█         | 357M/3.50G [00:30<04:18, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  10%|█         | 367M/3.50G [00:31<04:16, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  11%|█         | 377M/3.50G [00:32<04:15, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  11%|█         | 388M/3.50G [00:33<04:15, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  11%|█▏        | 398M/3.50G [00:34<04:29, 11.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  12%|█▏        | 409M/3.50G [00:35<04:14, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  12%|█▏        | 419M/3.50G [00:35<04:13, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  12%|█▏        | 430M/3.50G [00:36<04:12, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  13%|█▎        | 440M/3.50G [00:37<04:11, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  13%|█▎        | 451M/3.50G [00:38<04:10, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  13%|█▎        | 461M/3.50G [00:39<04:08, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  13%|█▎        | 472M/3.50G [00:40<04:08, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  14%|█▍        | 482M/3.50G [00:41<04:07, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  14%|█▍        | 493M/3.50G [00:41<04:06, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  14%|█▍        | 503M/3.50G [00:42<04:04, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  15%|█▍        | 514M/3.50G [00:43<04:04, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  15%|█▍        | 524M/3.50G [00:44<04:11, 11.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  15%|█▌        | 535M/3.50G [00:45<04:06, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  16%|█▌        | 545M/3.50G [00:46<04:04, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  16%|█▌        | 556M/3.50G [00:47<04:03, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  16%|█▌        | 566M/3.50G [00:48<04:01, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  16%|█▋        | 577M/3.50G [00:48<04:00, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  17%|█▋        | 587M/3.50G [00:49<03:59, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  17%|█▋        | 598M/3.50G [00:50<03:58, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  17%|█▋        | 608M/3.50G [00:51<03:57, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  18%|█▊        | 619M/3.50G [00:52<03:56, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  18%|█▊        | 629M/3.50G [00:53<03:55, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  18%|█▊        | 640M/3.50G [00:54<03:54, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  19%|█▊        | 650M/3.50G [00:54<03:58, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  19%|█▉        | 661M/3.50G [00:55<03:56, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  19%|█▉        | 671M/3.50G [00:56<03:54, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  19%|█▉        | 682M/3.50G [00:57<03:52, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  20%|█▉        | 692M/3.50G [00:58<03:51, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  20%|██        | 703M/3.50G [00:59<03:49, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  20%|██        | 713M/3.50G [01:00<03:48, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  21%|██        | 724M/3.50G [01:01<03:47, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  21%|██        | 734M/3.50G [01:01<03:46, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  21%|██▏       | 744M/3.50G [01:02<03:45, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  22%|██▏       | 755M/3.50G [01:03<03:45, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  22%|██▏       | 765M/3.50G [01:04<03:44, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  22%|██▏       | 776M/3.50G [01:05<03:49, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  22%|██▏       | 786M/3.50G [01:06<03:46, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  23%|██▎       | 797M/3.50G [01:07<03:44, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  23%|██▎       | 807M/3.50G [01:07<03:42, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  23%|██▎       | 818M/3.50G [01:08<03:42, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  24%|██▎       | 828M/3.50G [01:09<03:40, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  24%|██▍       | 839M/3.50G [01:10<03:39, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  24%|██▍       | 849M/3.50G [01:11<03:38, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  25%|██▍       | 860M/3.50G [01:12<03:36, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  25%|██▍       | 870M/3.50G [01:13<03:35, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  25%|██▌       | 881M/3.50G [01:13<03:34, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  25%|██▌       | 891M/3.50G [01:14<03:33, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  26%|██▌       | 902M/3.50G [01:15<03:37, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  26%|██▌       | 912M/3.50G [01:16<03:35, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  26%|██▋       | 923M/3.50G [01:17<03:33, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  27%|██▋       | 933M/3.50G [01:18<03:37, 11.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  27%|██▋       | 944M/3.50G [01:19<03:39, 11.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  27%|██▋       | 954M/3.50G [01:20<03:39, 11.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  28%|██▊       | 965M/3.50G [01:21<03:32, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  28%|██▊       | 975M/3.50G [01:22<03:36, 11.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  28%|██▊       | 986M/3.50G [01:22<03:26, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  28%|██▊       | 996M/3.50G [01:23<03:24, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  29%|██▉       | 1.01G/3.50G [01:24<03:26, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  29%|██▉       | 1.02G/3.50G [01:25<03:31, 11.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  29%|██▉       | 1.03G/3.50G [01:26<03:28, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  30%|██▉       | 1.04G/3.50G [01:27<03:26, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  30%|██▉       | 1.05G/3.50G [01:28<03:24, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  30%|███       | 1.06G/3.50G [01:28<03:22, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  31%|███       | 1.07G/3.50G [01:29<03:20, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  31%|███       | 1.08G/3.50G [01:30<03:19, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  31%|███       | 1.09G/3.50G [01:31<03:17, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  31%|███▏      | 1.10G/3.50G [01:32<03:16, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  32%|███▏      | 1.11G/3.50G [01:33<03:21, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  32%|███▏      | 1.12G/3.50G [01:34<03:15, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  32%|███▏      | 1.13G/3.50G [01:34<03:16, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  33%|███▎      | 1.14G/3.50G [01:36<03:25, 11.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  33%|███▎      | 1.15G/3.50G [01:36<03:20, 11.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  33%|███▎      | 1.16G/3.50G [01:37<03:17, 11.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  34%|███▎      | 1.17G/3.50G [01:38<03:14, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  34%|███▍      | 1.18G/3.50G [01:39<03:12, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  34%|███▍      | 1.20G/3.50G [01:40<03:10, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  34%|███▍      | 1.21G/3.50G [01:41<03:09, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  35%|███▍      | 1.22G/3.50G [01:42<03:08, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  35%|███▌      | 1.23G/3.50G [01:42<03:06, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  35%|███▌      | 1.24G/3.50G [01:43<03:05, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  36%|███▌      | 1.25G/3.50G [01:44<03:05, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  36%|███▌      | 1.26G/3.50G [01:45<03:04, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  36%|███▌      | 1.27G/3.50G [01:46<03:08, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  37%|███▋      | 1.28G/3.50G [01:47<03:06, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  37%|███▋      | 1.29G/3.50G [01:48<03:03, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  37%|███▋      | 1.30G/3.50G [01:48<03:01, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  37%|███▋      | 1.31G/3.50G [01:49<03:00, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  38%|███▊      | 1.32G/3.50G [01:50<02:59, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  38%|███▊      | 1.33G/3.50G [01:51<02:57, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  38%|███▊      | 1.34G/3.50G [01:52<02:57, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  39%|███▊      | 1.35G/3.50G [01:53<02:55, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  39%|███▉      | 1.36G/3.50G [01:54<02:55, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  39%|███▉      | 1.37G/3.50G [01:54<02:54, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  40%|███▉      | 1.38G/3.50G [01:55<02:53, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  40%|███▉      | 1.39G/3.50G [01:56<02:56, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  40%|████      | 1.41G/3.50G [01:57<02:54, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  40%|████      | 1.42G/3.50G [01:58<02:52, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  41%|████      | 1.43G/3.50G [01:59<02:51, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  41%|████      | 1.44G/3.50G [02:00<02:50, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  41%|████▏     | 1.45G/3.50G [02:01<02:48, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  42%|████▏     | 1.46G/3.50G [02:01<02:47, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  42%|████▏     | 1.47G/3.50G [02:02<02:46, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  42%|████▏     | 1.48G/3.50G [02:03<02:45, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  43%|████▎     | 1.49G/3.50G [02:04<02:45, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  43%|████▎     | 1.50G/3.50G [02:05<02:44, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  43%|████▎     | 1.51G/3.50G [02:06<02:43, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  43%|████▎     | 1.52G/3.50G [02:07<02:46, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  44%|████▎     | 1.53G/3.50G [02:08<02:44, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  44%|████▍     | 1.54G/3.50G [02:08<02:42, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  44%|████▍     | 1.55G/3.50G [02:09<02:41, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  45%|████▍     | 1.56G/3.50G [02:10<02:40, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  45%|████▍     | 1.57G/3.50G [02:11<02:38, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  45%|████▌     | 1.58G/3.50G [02:12<02:37, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  46%|████▌     | 1.59G/3.50G [02:13<02:36, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  46%|████▌     | 1.60G/3.50G [02:14<02:35, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  46%|████▌     | 1.61G/3.50G [02:14<02:34, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  46%|████▋     | 1.63G/3.50G [02:15<02:34, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  47%|████▋     | 1.64G/3.50G [02:16<02:43, 11.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  47%|████▋     | 1.65G/3.50G [02:17<02:32, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  47%|████▋     | 1.66G/3.50G [02:18<02:31, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  48%|████▊     | 1.67G/3.50G [02:19<02:30, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  48%|████▊     | 1.68G/3.50G [02:20<02:29, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  48%|████▊     | 1.69G/3.50G [02:20<02:28, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  49%|████▊     | 1.70G/3.50G [02:21<02:27, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  49%|████▉     | 1.71G/3.50G [02:22<02:26, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  49%|████▉     | 1.72G/3.50G [02:23<02:25, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  49%|████▉     | 1.73G/3.50G [02:24<02:25, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  50%|████▉     | 1.74G/3.50G [02:25<02:24, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  50%|█████     | 1.75G/3.50G [02:26<02:23, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  50%|█████     | 1.76G/3.50G [02:27<02:25, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  51%|█████     | 1.77G/3.50G [02:27<02:23, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  51%|█████     | 1.78G/3.50G [02:28<02:22, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  51%|█████     | 1.79G/3.50G [02:29<02:21, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  52%|█████▏    | 1.80G/3.50G [02:30<02:20, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  52%|█████▏    | 1.81G/3.50G [02:31<02:18, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  52%|█████▏    | 1.82G/3.50G [02:32<02:17, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  52%|█████▏    | 1.84G/3.50G [02:33<02:16, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  53%|█████▎    | 1.85G/3.50G [02:33<02:15, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  53%|█████▎    | 1.86G/3.50G [02:34<02:15, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  53%|█████▎    | 1.87G/3.50G [02:35<02:14, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  54%|█████▎    | 1.88G/3.50G [02:36<02:13, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  54%|█████▍    | 1.89G/3.50G [02:37<02:15, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  54%|█████▍    | 1.90G/3.50G [02:38<02:13, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  55%|█████▍    | 1.91G/3.50G [02:39<02:12, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  55%|█████▍    | 1.92G/3.50G [02:40<02:10, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  55%|█████▌    | 1.93G/3.50G [02:40<02:09, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  55%|█████▌    | 1.94G/3.50G [02:41<02:08, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  56%|█████▌    | 1.95G/3.50G [02:42<02:07, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  56%|█████▌    | 1.96G/3.50G [02:43<02:06, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  56%|█████▋    | 1.97G/3.50G [02:44<02:05, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  57%|█████▋    | 1.98G/3.50G [02:45<02:04, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  57%|█████▋    | 1.99G/3.50G [02:46<02:03, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  57%|█████▋    | 2.00G/3.50G [02:46<02:02, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  58%|█████▊    | 2.01G/3.50G [02:47<02:04, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  58%|█████▊    | 2.02G/3.50G [02:48<02:02, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  58%|█████▊    | 2.03G/3.50G [02:49<02:01, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  58%|█████▊    | 2.04G/3.50G [02:50<01:59, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  59%|█████▊    | 2.06G/3.50G [02:51<01:59, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  59%|█████▉    | 2.07G/3.50G [02:52<01:58, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  59%|█████▉    | 2.08G/3.50G [02:53<01:57, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  60%|█████▉    | 2.09G/3.50G [02:53<01:56, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  60%|█████▉    | 2.10G/3.50G [02:54<01:55, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  60%|██████    | 2.11G/3.50G [02:55<01:54, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  61%|██████    | 2.12G/3.50G [02:56<01:53, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  61%|██████    | 2.13G/3.50G [02:57<01:53, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  61%|██████    | 2.14G/3.50G [02:58<01:54, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  61%|██████▏   | 2.15G/3.50G [02:59<01:52, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  62%|██████▏   | 2.16G/3.50G [02:59<01:50, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  62%|██████▏   | 2.17G/3.50G [03:00<01:50, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  62%|██████▏   | 2.18G/3.50G [03:01<01:49, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  63%|██████▎   | 2.19G/3.50G [03:02<01:48, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  63%|██████▎   | 2.20G/3.50G [03:03<01:47, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  63%|██████▎   | 2.21G/3.50G [03:04<01:46, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  64%|██████▎   | 2.22G/3.50G [03:05<01:44, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  64%|██████▍   | 2.23G/3.50G [03:06<01:44, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  64%|██████▍   | 2.24G/3.50G [03:06<01:43, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  64%|██████▍   | 2.25G/3.50G [03:07<01:42, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  65%|██████▍   | 2.26G/3.50G [03:08<01:43, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  65%|██████▌   | 2.28G/3.50G [03:09<01:42, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  65%|██████▌   | 2.29G/3.50G [03:10<01:40, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  66%|██████▌   | 2.30G/3.50G [03:11<01:39, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  66%|██████▌   | 2.31G/3.50G [03:12<01:38, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  66%|██████▌   | 2.32G/3.50G [03:12<01:37, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  67%|██████▋   | 2.33G/3.50G [03:13<01:36, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  67%|██████▋   | 2.34G/3.50G [03:14<01:35, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  67%|██████▋   | 2.35G/3.50G [03:15<01:34, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  67%|██████▋   | 2.36G/3.50G [03:16<01:33, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  68%|██████▊   | 2.37G/3.50G [03:17<01:32, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  68%|██████▊   | 2.38G/3.50G [03:18<01:36, 11.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  68%|██████▊   | 2.39G/3.50G [03:19<01:31, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  69%|██████▊   | 2.40G/3.50G [03:19<01:30, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  69%|██████▉   | 2.41G/3.50G [03:20<01:29, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  69%|██████▉   | 2.42G/3.50G [03:21<01:28, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  69%|██████▉   | 2.43G/3.50G [03:22<01:27, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  70%|██████▉   | 2.44G/3.50G [03:23<01:26, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  70%|███████   | 2.45G/3.50G [03:24<01:25, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  70%|███████   | 2.46G/3.50G [03:25<01:24, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  71%|███████   | 2.47G/3.50G [03:25<01:24, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  71%|███████   | 2.49G/3.50G [03:26<01:23, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  71%|███████▏  | 2.50G/3.50G [03:27<01:22, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  72%|███████▏  | 2.51G/3.50G [03:28<01:25, 11.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  72%|███████▏  | 2.52G/3.50G [03:29<01:21, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  72%|███████▏  | 2.53G/3.50G [03:30<01:20, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  72%|███████▏  | 2.54G/3.50G [03:31<01:19, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  73%|███████▎  | 2.55G/3.50G [03:31<01:18, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  73%|███████▎  | 2.56G/3.50G [03:32<01:17, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  73%|███████▎  | 2.57G/3.50G [03:33<01:16, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  74%|███████▎  | 2.58G/3.50G [03:34<01:15, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  74%|███████▍  | 2.59G/3.50G [03:35<01:14, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  74%|███████▍  | 2.60G/3.50G [03:36<01:13, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  75%|███████▍  | 2.61G/3.50G [03:37<01:13, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  75%|███████▍  | 2.62G/3.50G [03:38<01:12, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  75%|███████▌  | 2.63G/3.50G [03:38<01:12, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  75%|███████▌  | 2.64G/3.50G [03:39<01:11, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  76%|███████▌  | 2.65G/3.50G [03:40<01:10, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  76%|███████▌  | 2.66G/3.50G [03:41<01:09, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  76%|███████▋  | 2.67G/3.50G [03:42<01:08, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  77%|███████▋  | 2.68G/3.50G [03:43<01:07, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  77%|███████▋  | 2.69G/3.50G [03:44<01:06, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  77%|███████▋  | 2.71G/3.50G [03:44<01:05, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  78%|███████▊  | 2.72G/3.50G [03:45<01:04, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  78%|███████▊  | 2.73G/3.50G [03:46<01:03, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  78%|███████▊  | 2.74G/3.50G [03:47<01:02, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  78%|███████▊  | 2.75G/3.50G [03:48<01:01, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  79%|███████▉  | 2.76G/3.50G [03:49<01:02, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  79%|███████▉  | 2.77G/3.50G [03:50<01:00, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  79%|███████▉  | 2.78G/3.50G [03:51<00:59, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  80%|███████▉  | 2.79G/3.50G [03:51<00:58, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  80%|███████▉  | 2.80G/3.50G [03:52<00:57, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  80%|████████  | 2.81G/3.50G [03:53<00:56, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  81%|████████  | 2.82G/3.50G [03:54<00:55, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  81%|████████  | 2.83G/3.50G [03:55<00:54, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  81%|████████  | 2.84G/3.50G [03:56<00:53, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  81%|████████▏ | 2.85G/3.50G [03:57<00:53, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  82%|████████▏ | 2.86G/3.50G [03:57<00:52, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  82%|████████▏ | 2.87G/3.50G [03:58<00:51, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  82%|████████▏ | 2.88G/3.50G [03:59<00:51, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  83%|████████▎ | 2.89G/3.50G [04:00<00:50, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  83%|████████▎ | 2.90G/3.50G [04:01<00:49, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  83%|████████▎ | 2.92G/3.50G [04:02<00:48, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  84%|████████▎ | 2.93G/3.50G [04:03<00:47, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  84%|████████▍ | 2.94G/3.50G [04:03<00:46, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  84%|████████▍ | 2.95G/3.50G [04:04<00:45, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  84%|████████▍ | 2.96G/3.50G [04:05<00:44, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  85%|████████▍ | 2.97G/3.50G [04:06<00:43, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  85%|████████▌ | 2.98G/3.50G [04:07<00:42, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  85%|████████▌ | 2.99G/3.50G [04:08<00:42, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  86%|████████▌ | 3.00G/3.50G [04:09<00:41, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  86%|████████▌ | 3.01G/3.50G [04:10<00:41, 11.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  86%|████████▋ | 3.02G/3.50G [04:10<00:40, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  87%|████████▋ | 3.03G/3.50G [04:11<00:39, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  87%|████████▋ | 3.04G/3.50G [04:12<00:38, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  87%|████████▋ | 3.05G/3.50G [04:13<00:37, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  87%|████████▋ | 3.06G/3.50G [04:14<00:36, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  88%|████████▊ | 3.07G/3.50G [04:15<00:35, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  88%|████████▊ | 3.08G/3.50G [04:16<00:34, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  88%|████████▊ | 3.09G/3.50G [04:16<00:33, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  89%|████████▊ | 3.10G/3.50G [04:17<00:32, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  89%|████████▉ | 3.11G/3.50G [04:18<00:31, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  89%|████████▉ | 3.12G/3.50G [04:19<00:31, 11.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  90%|████████▉ | 3.14G/3.50G [04:20<00:30, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  90%|████████▉ | 3.15G/3.50G [04:21<00:29, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  90%|█████████ | 3.16G/3.50G [04:22<00:28, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  90%|█████████ | 3.17G/3.50G [04:23<00:27, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  91%|█████████ | 3.18G/3.50G [04:23<00:26, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  91%|█████████ | 3.19G/3.50G [04:24<00:25, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  91%|█████████▏| 3.20G/3.50G [04:25<00:24, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  92%|█████████▏| 3.21G/3.50G [04:26<00:23, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  92%|█████████▏| 3.22G/3.50G [04:27<00:23, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  92%|█████████▏| 3.23G/3.50G [04:28<00:22, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  93%|█████████▎| 3.24G/3.50G [04:29<00:21, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  93%|█████████▎| 3.25G/3.50G [04:30<00:20, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  93%|█████████▎| 3.26G/3.50G [04:30<00:19, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  93%|█████████▎| 3.27G/3.50G [04:31<00:18, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  94%|█████████▍| 3.28G/3.50G [04:32<00:18, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  94%|█████████▍| 3.29G/3.50G [04:33<00:17, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  94%|█████████▍| 3.30G/3.50G [04:34<00:16, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  95%|█████████▍| 3.31G/3.50G [04:35<00:15, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  95%|█████████▍| 3.32G/3.50G [04:36<00:14, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  95%|█████████▌| 3.33G/3.50G [04:36<00:13, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  96%|█████████▌| 3.34G/3.50G [04:37<00:12, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  96%|█████████▌| 3.36G/3.50G [04:38<00:11, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  96%|█████████▌| 3.37G/3.50G [04:39<00:11, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  96%|█████████▋| 3.38G/3.50G [04:40<00:10, 11.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  97%|█████████▋| 3.39G/3.50G [04:41<00:09, 12.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  97%|█████████▋| 3.40G/3.50G [04:42<00:08, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  97%|█████████▋| 3.41G/3.50G [04:42<00:07, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  98%|█████████▊| 3.42G/3.50G [04:43<00:06, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  98%|█████████▊| 3.43G/3.50G [04:44<00:05, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  98%|█████████▊| 3.44G/3.50G [04:45<00:05, 12.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  99%|█████████▊| 3.45G/3.50G [04:46<00:04, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  99%|█████████▉| 3.46G/3.50G [04:47<00:03, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  99%|█████████▉| 3.47G/3.50G [04:48<00:02, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  99%|█████████▉| 3.48G/3.50G [04:49<00:01, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin: 100%|█████████▉| 3.49G/3.50G [04:49<00:00, 12.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin: 100%|██████████| 3.50G/3.50G [04:50<00:00, 12.0MB/s]\u001b[A\n",
      "Downloading shards: 100%|██████████| 2/2 [18:52<00:00, 566.27s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.37s/it]\n",
      "generation_config.json: 100%|██████████| 188/188 [00:00<00:00, 76.3kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== cendol-llama2-7b =====\n",
      "prompt: Apa itu STNK?\n",
      "response: <s> Apa itu STNK?</s>\n",
      "prompt: Gimana caranya perpanjang STNK?\n",
      "response: <s> Gimana caranya perpanjang STNK?</s>\n",
      "prompt: Tutorial perpanjang STNK?\n",
      "response: <s> Tutorial perpanjang STNK?</s>\n",
      "prompt: Di mana perpanjang STNK?\n",
      "response: <s> Di mana perpanjang STNK?</s>\n",
      "prompt: Cara mengurus STNK yang sudah tidak berlaku?\n",
      "response: <s> Cara mengurus STNK yang sudah tidak berlaku?</s>\n",
      "prompt: Cara mengurus KTP hilang?\n",
      "response: <s> Cara mengurus KTP hilang? How to lose your ID card?</s>\n",
      "prompt: KTP gue ilang coy?\n",
      "response: <s> KTP gue ilang coy?</s>\n",
      "prompt: Kapan harus bayar pajak?\n",
      "response: <s> Kapan harus bayar pajak?</s>\n",
      "prompt: Gimana cara ngurus NPWP?\n",
      "response: <s> Gimana cara ngurus NPWP?</s>\n",
      "prompt: Cara pembuatan NPWP?\n",
      "response: <s> Cara pembuatan NPWP?</s>\n",
      "prompt: Apa itu BPJS?\n",
      "response: <s> Apa itu BPJS?</s>\n",
      "prompt: Gimana caranya daftar BPJS?\n",
      "response: <s> Gimana caranya daftar BPJS?</s>\n",
      "prompt: Bagaimana prosedur daftar BPJS Ketenagakerjaan?\n",
      "response: <s> Bagaimana prosedur daftar BPJS Ketenagakerjaan?</s>\n",
      "prompt: 5 tips lolos tes CPNS:?\n",
      "response: <s> 5 tips lolos tes CPNS:? 5 Tips Lolos Tes CPNS:</s>\n",
      "prompt: Trik diterima tes masuk PNS?\n",
      "response: <s> Trik diterima tes masuk PNS?</s>\n",
      "prompt: Bagaimana supaya bisa masuk PNS?\n",
      "response: <s> Bagaimana supaya bisa masuk PNS?</s>\n",
      "prompt: Tips dan trik masuk kuliah di UI?\n",
      "response: <s> Tips dan trik masuk kuliah di UI?</s>\n",
      "prompt: Cara ampuh diterima kuliah di ITB?\n",
      "response: <s> Cara ampuh diterima kuliah di ITB?</s>\n",
      "prompt: Bagaimana caranya lolos SIMAK UI?\n",
      "response: <s> Bagaimana caranya lolos SIMAK UI?</s>\n",
      "prompt: Bagaimana cara lolos SNMBTN?\n",
      "response: <s> Bagaimana cara lolos SNMBTN?</s>\n",
      "prompt: Gimana caranya bisa masuk Binus?\n",
      "response: <s> Gimana caranya bisa masuk Binus?</s>\n",
      "prompt: Tips masuk UGM dong?\n",
      "response: <s> Tips masuk UGM dong?</s>\n",
      "prompt: Siapa Jokowi?\n",
      "response: <s> Siapa Jokowi?</s>\n",
      "prompt: Siapa Anies?\n",
      "response: <s> Siapa Anies?</s>\n",
      "prompt: Siapa Ridwan Kamil?\n",
      "response: <s> Siapa Ridwan Kamil?</s>\n",
      "prompt: Siapa Aldi Taher?\n",
      "response: <s> Siapa Aldi Taher?</s>\n",
      "prompt: Siapa Megawati?\n",
      "response: <s> Siapa Megawati?</s>\n",
      "prompt: Siapa Nadiem Makarim?\n",
      "response: <s> Siapa Nadiem Makarim?</s>\n",
      "prompt: Siapa Prabowo Subianto?\n",
      "response: <s> Siapa Prabowo Subianto?</s>\n",
      "prompt: Siapa Syahrini?\n",
      "response: <s> Siapa Syahrini?</s>\n",
      "prompt: Siapa Sherina?\n",
      "response: <s> Siapa Sherina?</s>\n",
      "prompt: 5 destinasi wisata favorit di Bali?\n",
      "response: <s> 5 destinasi wisata favorit di Bali?</s>\n",
      "prompt: Buat travel plan healing ke Jogja?\n",
      "response: <s> Buat travel plan healing ke Jogja? Rencana perjalanan pulih ke Jogja?</s>\n",
      "prompt: Kalau lagi di Jakarta, bagusnya main ke mana aja?\n",
      "response: <s> Kalau lagi di Jakarta, bagusnya main ke mana aja?</s>\n",
      "prompt: Apa tempat wisata paling bagus di Medan?\n",
      "response: <s> Apa tempat wisata paling bagus di Medan?</s>\n",
      "prompt: Bagaimana caranya jadi mitra GoJek?\n",
      "response: <s> Bagaimana caranya jadi mitra GoJek? Beberapa tips untuk menjadi mitra GoJek?</s>\n",
      "prompt: Akun GoPay saya terblokir?\n",
      "response: <s> Akun GoPay saya terblokir?</s>\n",
      "prompt: Gimana caranya top-up OVO?\n",
      "response: <s> Gimana caranya top-up OVO?</s>\n",
      "prompt: Pesen cendol gimana?\n",
      "response: <s> Pesen cendol gimana?</s>\n",
      "prompt: Pesen gojek gimana?\n",
      "response: <s> Pesen gojek gimana?</s>\n",
      "prompt: Belanja di tokped caranya gimana?\n",
      "response: <s> Belanja di tokped caranya gimana?</s>\n",
      "prompt: Cara sukses jualan di Shopee?\n",
      "response: <s> Cara sukses jualan di Shopee?</s>\n",
      "prompt: Tips healing ampuh dong?\n",
      "response: <s> Tips healing ampuh dong?</s>\n",
      "prompt: Tips anti galau ala anak jaksel?\n",
      "response: <s> Tips anti galau ala anak jaksel?</s>\n",
      "prompt: Pesen grab gimana?\n",
      "response: <s> Pesen grab gimana?</s>\n",
      "prompt: Pesen taksi gimana?\n",
      "response: <s> Pesen taksi gimana?</s>\n",
      "prompt: Tips sukses jualan di Tiktok?\n",
      "response: <s> Tips sukses jualan di Tiktok?</s>\n",
      "prompt: Tips sukses dalam semalam?\n",
      "response: <s> Tips sukses dalam semalam?</s>\n",
      "prompt: Tips sukses cpns?\n",
      "response: <s> Tips sukses cpns?</s>\n",
      "prompt: Tips sukses sistem kebut semalam?\n",
      "response: <s> Tips sukses sistem kebut semalam?</s>\n",
      "prompt: Mau jalan-jalan di Pluit, kemana ya?\n",
      "response: <s> Mau jalan-jalan di Pluit, kemana ya?</s>\n",
      "prompt: Mau jalan-jalan di Jaksel, kemana ya?\n",
      "response: <s> Mau jalan-jalan di Jaksel, kemana ya?</s>\n",
      "prompt: Mau jalan-jalan di PIM, kemana ya?\n",
      "response: <s> Mau jalan-jalan di PIM, kemana ya?</s>\n",
      "prompt: Mau jalan-jalan di GI, kemana ya?\n",
      "response: <s> Mau jalan-jalan di GI, kemana ya?</s>\n",
      "prompt: Kalau mau kuliah, bagusnya kuliah kemana ya?\n",
      "response: <s> Kalau mau kuliah, bagusnya kuliah kemana ya?</s>\n",
      "prompt: Kalau mau kuliah, apa cuma kuliah negeri aja yang bagus?\n",
      "response: <s> Kalau mau kuliah, apa cuma kuliah negeri aja yang bagus?</s>\n",
      "prompt: Kalau mau kuliah, apa cuma kuliah swasta aja yang bagus?\n",
      "response: <s> Kalau mau kuliah, apa cuma kuliah swasta aja yang bagus?</s>\n",
      "prompt: Siapa anaknya Jokowi?\n",
      "response: <s> Siapa anaknya Jokowi?</s>\n",
      "prompt: Siapa anaknya Soekarno?\n",
      "response: <s> Siapa anaknya Soekarno?</s>\n",
      "prompt: Siapa presiden Indonesia yang pertama?\n",
      "response: <s> Siapa presiden Indonesia yang pertama?</s>\n",
      "prompt: Siapa presiden Indonesia yang kedua?\n",
      "response: <s> Siapa presiden Indonesia yang kedua?</s>\n",
      "prompt: Apa artinya sebelum negara api menyerang?\n",
      "response: <s> Apa artinya sebelum negara api menyerang?</s>\n",
      "prompt: Jual mobil perlu BPKB ngga?\n",
      "response: <s> Jual mobil perlu BPKB ngga? http://dlvr.it/8jMFFG</s>\n",
      "prompt: Jual mobil tanpa BPKB?\n",
      "response: <s> Jual mobil tanpa BPKB? Buy a car without BPKB?</s>\n",
      "prompt: Mendingan gw mampir pegadaian ngga ya?\n",
      "response: <s> Mendingan gw mampir pegadaian ngga ya? Mendingan saya mampir pegadaian tidak ya?</s>\n",
      "prompt: Cicil rumah bisa via KPR?\n",
      "response: <s> Cicil rumah bisa via KPR?</s>\n",
      "prompt: Gimana caranya KPR murah?\n",
      "response: <s> Gimana caranya KPR murah?</s>\n",
      "prompt: Tips sukses KPR?\n",
      "response: <s> Tips sukses KPR?</s>\n",
      "prompt: Kredit bunga rendah?\n",
      "response: <s> Kredit bunga rendah?</s>\n",
      "prompt: Kredit motor dong?\n",
      "response: <s> Kredit motor dong?</s>\n",
      "prompt: Gimana cara manfaatin KTP ganda?\n",
      "response: <s> Gimana cara manfaatin KTP ganda?</s>\n",
      "prompt: Tips sukses jualan di Tokped?\n",
      "response: <s> Tips sukses jualan di Tokped?</s>\n",
      "prompt: Tips sukses jualan di Tokopedia?\n",
      "response: <s> Tips sukses jualan di Tokopedia?</s>\n",
      "prompt: Gimana cara beli ketoprak?\n",
      "response: <s> Gimana cara beli ketoprak?</s>\n",
      "prompt: Gimana cara bikin ketoprak?\n",
      "response: <s> Gimana cara bikin ketoprak?</s>\n",
      "prompt: Ketoprak yg enak yg kayak apa?\n",
      "response: <s> Ketoprak yg enak yg kayak apa?</s>\n",
      "prompt: Gimana cara beli gado-gado?\n",
      "response: <s> Gimana cara beli gado-gado?</s>\n",
      "prompt: Gimana cara bikin gado-gado?\n",
      "response: <s> Gimana cara bikin gado-gado?</s>\n",
      "prompt: Gado-gado yg enak yg kayak apa?\n",
      "response: <s> Gado-gado yg enak yg kayak apa?</s>\n",
      "prompt: Makanan khas Indo apa ya yang enak?\n",
      "response: <s> Makanan khas Indo apa ya yang enak?</s>\n",
      "prompt: Minta saran oleh-oleh khas Indo dong?\n",
      "response: <s> Minta saran oleh-oleh khas Indo dong?</s>\n",
      "prompt: Makanan khas Jakarta apa ya yang enak?\n",
      "response: <s> Makanan khas Jakarta apa ya yang enak?</s>\n",
      "prompt: Minta saran oleh-oleh khas Jakarta dong?\n",
      "response: <s> Minta saran oleh-oleh khas Jakarta dong?</s>\n",
      "prompt: Makanan khas Bandung apa ya yang enak?\n",
      "response: <s> Makanan khas Bandung apa ya yang enak?</s>\n",
      "prompt: Minta saran oleh-oleh khas Bandung dong?\n",
      "response: <s> Minta saran oleh-oleh khas Bandung dong?</s>\n",
      "prompt: Apa bedanya pecel lele sama lele?\n",
      "response: <s> Apa bedanya pecel lele sama lele?</s>\n",
      "prompt: Apa bedanya pecel lele sama pecel?\n",
      "response: <s> Apa bedanya pecel lele sama pecel?</s>\n",
      "prompt: Apa bedanya ketoprak dan gado-gado?\n",
      "response: <s> Apa bedanya ketoprak dan gado-gado?</s>\n",
      "prompt: Apa bedanya ketoprak dan karedok?\n",
      "response: <s> Apa bedanya ketoprak dan karedok?</s>\n",
      "prompt: Apa bedanya gado-gado dan karedok?\n",
      "response: <s> Apa bedanya gado-gado dan karedok?</s>\n",
      "prompt: Akun Grab saya terblokir?\n",
      "response: <s> Akun Grab saya terblokir?</s>\n",
      "prompt: Kenapa Jakarta macet banget ya?\n",
      "response: <s> Kenapa Jakarta macet banget ya?</s>\n",
      "prompt: Gimana caranya jadi presiden?\n",
      "response: <s> Gimana caranya jadi presiden?</s>\n",
      "prompt: Gimana caranya jadi gubernur?\n",
      "response: <s> Gimana caranya jadi gubernur?</s>\n",
      "prompt: Gimana caranya jadi ketua RT?\n",
      "response: <s> Gimana caranya jadi ketua RT?</s>\n",
      "prompt: Kenapa ngga ada yang mau jadi ketua RT?\n",
      "response: <s> Kenapa ngga ada yang mau jadi ketua RT?</s>\n",
      "prompt: Apa sih bedanya RT dan RW?\n",
      "response: <s> Apa sih bedanya RT dan RW?</s>\n",
      "prompt: Apaan itu kelurahan dan kecamatan?\n",
      "response: <s> Apaan itu kelurahan dan kecamatan?</s>\n",
      "prompt: Minta review product Wardah dong?\n",
      "response: <s> Minta review product Wardah dong?</s>\n",
      "prompt: Bisakah Anda jelaskan ulasan pelanggan yang negatif dan positif dari pelanggan yang telah membeli dan menggunakan Wardah untuk waktu yang cukup lama?\n",
      "response: <s> Bisakah Anda jelaskan ulasan pelanggan yang negatif dan positif dari pelanggan yang telah membeli dan menggunakan Wardah untuk waktu yang cukup lama?</s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 6/6 [00:50<00:00,  8.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== cendol-llama2-13b-merged =====\n",
      "prompt: Apa itu STNK?\n",
      "response: <s> Apa itu STNK?</s>\n",
      "prompt: Gimana caranya perpanjang STNK?\n",
      "response: <s> Gimana caranya perpanjang STNK?</s>\n",
      "prompt: Tutorial perpanjang STNK?\n",
      "response: <s> Tutorial perpanjang STNK?</s>\n",
      "prompt: Di mana perpanjang STNK?\n",
      "response: <s> Di mana perpanjang STNK?</s>\n",
      "prompt: Cara mengurus STNK yang sudah tidak berlaku?\n",
      "response: <s> Cara mengurus STNK yang sudah tidak berlaku?</s>\n",
      "prompt: Cara mengurus KTP hilang?\n",
      "response: <s> Cara mengurus KTP hilang?</s>\n",
      "prompt: KTP gue ilang coy?\n",
      "response: <s> KTP gue ilang coy?!?!?! FYI. My ID card is missing?!?!?! FYI.</s>\n",
      "prompt: Kapan harus bayar pajak?\n",
      "response: <s> Kapan harus bayar pajak?</s>\n",
      "prompt: Gimana cara ngurus NPWP?\n",
      "response: <s> Gimana cara ngurus NPWP?</s>\n",
      "prompt: Cara pembuatan NPWP?\n",
      "response: <s> Cara pembuatan NPWP?</s>\n",
      "prompt: Apa itu BPJS?\n",
      "response: <s> Apa itu BPJS?</s>\n",
      "prompt: Gimana caranya daftar BPJS?\n",
      "response: <s> Gimana caranya daftar BPJS?</s>\n",
      "prompt: Bagaimana prosedur daftar BPJS Ketenagakerjaan?\n",
      "response: <s> Bagaimana prosedur daftar BPJS Ketenagakerjaan?</s>\n",
      "prompt: 5 tips lolos tes CPNS:?\n",
      "response: <s> 5 tips lolos tes CPNS:?</s>\n",
      "prompt: Trik diterima tes masuk PNS?\n",
      "response: <s> Trik diterima tes masuk PNS?</s>\n",
      "prompt: Bagaimana supaya bisa masuk PNS?\n",
      "response: <s> Bagaimana supaya bisa masuk PNS?</s>\n",
      "prompt: Tips dan trik masuk kuliah di UI?\n",
      "response: <s> Tips dan trik masuk kuliah di UI?</s>\n",
      "prompt: Cara ampuh diterima kuliah di ITB?\n",
      "response: <s> Cara ampuh diterima kuliah di ITB?</s>\n",
      "prompt: Bagaimana caranya lolos SIMAK UI?\n",
      "response: <s> Bagaimana caranya lolos SIMAK UI?</s>\n",
      "prompt: Bagaimana cara lolos SNMBTN?\n",
      "response: <s> Bagaimana cara lolos SNMBTN?</s>\n",
      "prompt: Gimana caranya bisa masuk Binus?\n",
      "response: <s> Gimana caranya bisa masuk Binus?</s>\n",
      "prompt: Tips masuk UGM dong?\n",
      "response: <s> Tips masuk UGM dong? oi, tips masuk UGM dong?</s>\n",
      "prompt: Siapa Jokowi?\n",
      "response: <s> Siapa Jokowi?</s>\n",
      "prompt: Siapa Anies?\n",
      "response: <s> Siapa Anies? Aanies is a Muslim, and he is a member of the Muslim Brotherhood Ikhwan web site.</s>\n",
      "prompt: Siapa Ridwan Kamil?\n",
      "response: <s> Siapa Ridwan Kamil?</s>\n",
      "prompt: Siapa Aldi Taher?\n",
      "response: <s> Siapa Aldi Taher?</s>\n",
      "prompt: Siapa Megawati?\n",
      "response: <s> Siapa Megawati? (Indonesian: Siapakah Megawati?</s>\n",
      "prompt: Siapa Nadiem Makarim?\n",
      "response: <s> Siapa Nadiem Makarim? The profile of Nadiem Makarim.</s>\n",
      "prompt: Siapa Prabowo Subianto?\n",
      "response: <s> Siapa Prabowo Subianto?</s>\n",
      "prompt: Siapa Syahrini?\n",
      "response: <s> Siapa Syahrini? Siapa Syahrini?</s>\n",
      "prompt: Siapa Sherina?\n",
      "response: <s> Siapa Sherina?</s>\n",
      "prompt: 5 destinasi wisata favorit di Bali?\n",
      "response: <s> 5 destinasi wisata favorit di Bali?</s>\n",
      "prompt: Buat travel plan healing ke Jogja?\n",
      "response: <s> Buat travel plan healing ke Jogja? Lihat kami!</s>\n",
      "prompt: Kalau lagi di Jakarta, bagusnya main ke mana aja?\n",
      "response: <s> Kalau lagi di Jakarta, bagusnya main ke mana aja?</s>\n",
      "prompt: Apa tempat wisata paling bagus di Medan?\n",
      "response: <s> Apa tempat wisata paling bagus di Medan?</s>\n",
      "prompt: Bagaimana caranya jadi mitra GoJek?\n",
      "response: <s> Bagaimana caranya jadi mitra GoJek?</s>\n",
      "prompt: Akun GoPay saya terblokir?\n",
      "response: <s> Akun GoPay saya terblokir?</s>\n",
      "prompt: Gimana caranya top-up OVO?\n",
      "response: <s> Gimana caranya top-up OVO?</s>\n",
      "prompt: Pesen cendol gimana?\n",
      "response: <s> Pesen cendol gimana?</s>\n",
      "prompt: Pesen gojek gimana?\n",
      "response: <s> Pesen gojek gimana?</s>\n",
      "prompt: Belanja di tokped caranya gimana?\n",
      "response: <s> Belanja di tokped caranya gimana?</s>\n",
      "prompt: Cara sukses jualan di Shopee?\n",
      "response: <s> Cara sukses jualan di Shopee? Promo code.</s>\n",
      "prompt: Tips healing ampuh dong?\n",
      "response: <s> Tips healing ampuh dong?</s>\n",
      "prompt: Tips anti galau ala anak jaksel?\n",
      "response: <s> Tips anti galau ala anak jaksel?</s>\n",
      "prompt: Pesen grab gimana?\n",
      "response: <s> Pesen grab gimana?</s>\n",
      "prompt: Pesen taksi gimana?\n",
      "response: <s> Pesen taksi gimana? Bus or train?</s>\n",
      "prompt: Tips sukses jualan di Tiktok?\n",
      "response: <s> Tips sukses jualan di Tiktok?</s>\n",
      "prompt: Tips sukses dalam semalam?\n",
      "response: <s> Tips sukses dalam semalam?</s>\n",
      "prompt: Tips sukses cpns?\n",
      "response: <s> Tips sukses cpns?</s>\n",
      "prompt: Tips sukses sistem kebut semalam?\n",
      "response: <s> Tips sukses sistem kebut semalam?</s>\n",
      "prompt: Mau jalan-jalan di Pluit, kemana ya?\n",
      "response: <s> Mau jalan-jalan di Pluit, kemana ya?</s>\n",
      "prompt: Mau jalan-jalan di Jaksel, kemana ya?\n",
      "response: <s> Mau jalan-jalan di Jaksel, kemana ya?</s>\n",
      "prompt: Mau jalan-jalan di PIM, kemana ya?\n",
      "response: <s> Mau jalan-jalan di PIM, kemana ya?</s>\n",
      "prompt: Mau jalan-jalan di GI, kemana ya?\n",
      "response: <s> Mau jalan-jalan di GI, kemana ya?</s>\n",
      "prompt: Kalau mau kuliah, bagusnya kuliah kemana ya?\n",
      "response: <s> Kalau mau kuliah, bagusnya kuliah kemana ya?</s>\n",
      "prompt: Kalau mau kuliah, apa cuma kuliah negeri aja yang bagus?\n",
      "response: <s> Kalau mau kuliah, apa cuma kuliah negeri aja yang bagus?</s>\n",
      "prompt: Kalau mau kuliah, apa cuma kuliah swasta aja yang bagus?\n",
      "response: <s> Kalau mau kuliah, apa cuma kuliah swasta aja yang bagus?</s>\n",
      "prompt: Siapa anaknya Jokowi?\n",
      "response: <s> Siapa anaknya Jokowi?</s>\n",
      "prompt: Siapa anaknya Soekarno?\n",
      "response: <s> Siapa anaknya Soekarno?</s>\n",
      "prompt: Siapa presiden Indonesia yang pertama?\n",
      "response: <s> Siapa presiden Indonesia yang pertama? Sukaruhun</s>\n",
      "prompt: Siapa presiden Indonesia yang kedua?\n",
      "response: <s> Siapa presiden Indonesia yang kedua?</s>\n",
      "prompt: Apa artinya sebelum negara api menyerang?\n",
      "response: <s> Apa artinya sebelum negara api menyerang?</s>\n",
      "prompt: Jual mobil perlu BPKB ngga?\n",
      "response: <s> Jual mobil perlu BPKB ngga?</s>\n",
      "prompt: Jual mobil tanpa BPKB?\n",
      "response: <s> Jual mobil tanpa BPKB? Mobil tanpa BPKB kaina, tolong nih otomatis tanpa otomatis tanpa BPKB?</s>\n",
      "prompt: Mendingan gw mampir pegadaian ngga ya?\n",
      "response: <s> Mendingan gw mampir pegadaian ngga ya? :D</s>\n",
      "prompt: Cicil rumah bisa via KPR?\n",
      "response: <s> Cicil rumah bisa via KPR?</s>\n",
      "prompt: Gimana caranya KPR murah?\n",
      "response: <s> Gimana caranya KPR murah?</s>\n",
      "prompt: Tips sukses KPR?\n",
      "response: <s> Tips sukses KPR?</s>\n",
      "prompt: Kredit bunga rendah?\n",
      "response: <s> Kredit bunga rendah?</s>\n",
      "prompt: Kredit motor dong?\n",
      "response: <s> Kredit motor dong?</s>\n",
      "prompt: Gimana cara manfaatin KTP ganda?\n",
      "response: <s> Gimana cara manfaatin KTP ganda?</s>\n",
      "prompt: Tips sukses jualan di Tokped?\n",
      "response: <s> Tips sukses jualan di Tokped?</s>\n",
      "prompt: Tips sukses jualan di Tokopedia?\n",
      "response: <s> Tips sukses jualan di Tokopedia?</s>\n",
      "prompt: Gimana cara beli ketoprak?\n",
      "response: <s> Gimana cara beli ketoprak?</s>\n",
      "prompt: Gimana cara bikin ketoprak?\n",
      "response: <s> Gimana cara bikin ketoprak?</s>\n",
      "prompt: Ketoprak yg enak yg kayak apa?\n",
      "response: <s> Ketoprak yg enak yg kayak apa?</s>\n",
      "prompt: Gimana cara beli gado-gado?\n",
      "response: <s> Gimana cara beli gado-gado?</s>\n",
      "prompt: Gimana cara bikin gado-gado?\n",
      "response: <s> Gimana cara bikin gado-gado?</s>\n",
      "prompt: Gado-gado yg enak yg kayak apa?\n",
      "response: <s> Gado-gado yg enak yg kayak apa?</s>\n",
      "prompt: Makanan khas Indo apa ya yang enak?\n",
      "response: <s> Makanan khas Indo apa ya yang enak?</s>\n",
      "prompt: Minta saran oleh-oleh khas Indo dong?\n",
      "response: <s> Minta saran oleh-oleh khas Indo dong?</s>\n",
      "prompt: Makanan khas Jakarta apa ya yang enak?\n",
      "response: <s> Makanan khas Jakarta apa ya yang enak?</s>\n",
      "prompt: Minta saran oleh-oleh khas Jakarta dong?\n",
      "response: <s> Minta saran oleh-oleh khas Jakarta dong?</s>\n",
      "prompt: Makanan khas Bandung apa ya yang enak?\n",
      "response: <s> Makanan khas Bandung apa ya yang enak?</s>\n",
      "prompt: Minta saran oleh-oleh khas Bandung dong?\n",
      "response: <s> Minta saran oleh-oleh khas Bandung dong?</s>\n",
      "prompt: Apa bedanya pecel lele sama lele?\n",
      "response: <s> Apa bedanya pecel lele sama lele?</s>\n",
      "prompt: Apa bedanya pecel lele sama pecel?\n",
      "response: <s> Apa bedanya pecel lele sama pecel?</s>\n",
      "prompt: Apa bedanya ketoprak dan gado-gado?\n",
      "response: <s> Apa bedanya ketoprak dan gado-gado?</s>\n",
      "prompt: Apa bedanya ketoprak dan karedok?\n",
      "response: <s> Apa bedanya ketoprak dan karedok?</s>\n",
      "prompt: Apa bedanya gado-gado dan karedok?\n",
      "response: <s> Apa bedanya gado-gado dan karedok?</s>\n",
      "prompt: Akun Grab saya terblokir?\n",
      "response: <s> Akun Grab saya terblokir?</s>\n",
      "prompt: Kenapa Jakarta macet banget ya?\n",
      "response: <s> Kenapa Jakarta macet banget ya?</s>\n",
      "prompt: Gimana caranya jadi presiden?\n",
      "response: <s> Gimana caranya jadi presiden?</s>\n",
      "prompt: Gimana caranya jadi gubernur?\n",
      "response: <s> Gimana caranya jadi gubernur?</s>\n",
      "prompt: Gimana caranya jadi ketua RT?\n",
      "response: <s> Gimana caranya jadi ketua RT?</s>\n",
      "prompt: Kenapa ngga ada yang mau jadi ketua RT?\n",
      "response: <s> Kenapa ngga ada yang mau jadi ketua RT?</s>\n",
      "prompt: Apa sih bedanya RT dan RW?\n",
      "response: <s> Apa sih bedanya RT dan RW?</s>\n",
      "prompt: Apaan itu kelurahan dan kecamatan?\n",
      "response: <s> Apaan itu kelurahan dan kecamatan?</s>\n",
      "prompt: Minta review product Wardah dong?\n",
      "response: <s> Minta review product Wardah dong? :) ~Junko</s>\n",
      "prompt: Bisakah Anda jelaskan ulasan pelanggan yang negatif dan positif dari pelanggan yang telah membeli dan menggunakan Wardah untuk waktu yang cukup lama?\n",
      "response: <s> Bisakah Anda jelaskan ulasan pelanggan yang negatif dan positif dari pelanggan yang telah membeli dan menggunakan Wardah untuk waktu yang cukup lama?</s>\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('indonlp/cendol-llama2-13b-merged', token='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')\n",
    "for model_path in [\n",
    "    'indonlp/cendol-llama2-7b',\n",
    "    'indonlp/cendol-llama2-13b-merged'\n",
    "]:\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_path, token='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')\n",
    "    model_name = model_path.split('/')[-1]\n",
    "    print(f'===== {model_name} =====')\n",
    "    responses = []\n",
    "    for prompt in prompts:\n",
    "        responses.append(\n",
    "            tokenizer.decode(\n",
    "                model.generate(tokenizer(prompt, return_tensors='pt')['input_ids'], top_p=0.9, top_k=50, min_length=0, max_length=512, do_sample=True)[0]\n",
    "            )\n",
    "        )\n",
    "        print(f'prompt: {prompt}')\n",
    "        print(f'response: {responses[-1]}')\n",
    "    pd.DataFrame({'prompts': prompts, 'responses': responses}).to_csv(f'./gen_save/{model_name}_v1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cce158",
   "metadata": {},
   "source": [
    "# Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25101c83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== bloomz-7b1 =====\n",
      "prompt: Apa itu STNK?\n",
      "response:  Surat Tanda Nomor Kendaraan\n",
      "prompt: Gimana caranya perpanjang STNK?\n",
      "response:  Via internet\n",
      "prompt: Tutorial perpanjang STNK?\n",
      "response:  Yes\n",
      "prompt: Di mana perpanjang STNK?\n",
      "response:  kantor samsat\n",
      "prompt: Cara mengurus STNK yang sudah tidak berlaku?\n",
      "response:  Anda bisa langsung pergi ke kantor polisi untuk mengurusnya.\n",
      "prompt: Cara mengurus KTP hilang?\n",
      "response:  Coba hubungi kelurahan\n",
      "prompt: KTP gue ilang coy?\n",
      "response:  Oh, ya saya tau..\n",
      "prompt: Kapan harus bayar pajak?\n",
      "response:  Setiap tahun\n",
      "prompt: Gimana cara ngurus NPWP?\n",
      "response:  Cek tabel yang disediakan di situs Kementerian Keuangan.\n",
      "prompt: Cara pembuatan NPWP?\n",
      "response:  Anda perlu mengisi formulir dan membayar biaya yang diminta.\n",
      "prompt: Apa itu BPJS?\n",
      "response:  Badan Penyelenggara Jaminan Sosial\n",
      "prompt: Gimana caranya daftar BPJS?\n",
      "response:  Menelepon nomor 135\n",
      "prompt: Bagaimana prosedur daftar BPJS Ketenagakerjaan?\n",
      "response:  bisa melalui aplikasi Mobile JKK.\n",
      "prompt: 5 tips lolos tes CPNS:?\n",
      "response:  Sabar, jangan terlalu ambisius dan belajar\n",
      "prompt: Trik diterima tes masuk PNS?\n",
      "response:  Bisa\n",
      "prompt: Bagaimana supaya bisa masuk PNS?\n",
      "response:  lulus tes\n",
      "prompt: Tips dan trik masuk kuliah di UI?\n",
      "response:  Universitas Indonesia\n",
      "prompt: Cara ampuh diterima kuliah di ITB?\n",
      "response:  Saya tidak punya jawaban karena saya tidak pernah diterima ITB.\n",
      "prompt: Bagaimana caranya lolos SIMAK UI?\n",
      "response:  Anda bisa mendaftar program SIMAK UI melalui situs resmi kampus\n",
      "prompt: Bagaimana cara lolos SNMBTN?\n",
      "response:  harus memenuhi syarat yang sudah ditentukan\n",
      "prompt: Gimana caranya bisa masuk Binus?\n",
      "response:  bisa melalui jalur SNMPTN\n",
      "prompt: Tips masuk UGM dong?\n",
      "response:  Nuhun.\n",
      "prompt: Siapa Jokowi?\n",
      "response:  Presiden Republik Indonesia\n",
      "prompt: Siapa Anies?\n",
      "response:  gubernur DKI Jakarta\n",
      "prompt: Siapa Ridwan Kamil?\n",
      "response:  Gubernur Jawa Barat\n",
      "prompt: Siapa Aldi Taher?\n",
      "response:  aktor dan model\n",
      "prompt: Siapa Megawati?\n",
      "response:  Ketua Dewan Perwakilan Rakyat.\n",
      "prompt: Siapa Nadiem Makarim?\n",
      "response:  Bos Gojek\n",
      "prompt: Siapa Prabowo Subianto?\n",
      "response:  Presiden RI\n",
      "prompt: Siapa Syahrini?\n",
      "response:  Penyanyi terkenal di Indonesia\n",
      "prompt: Siapa Sherina?\n",
      "response:  Putri mantan Wakil Presiden AS Dick Cheney\n",
      "prompt: 5 destinasi wisata favorit di Bali?\n",
      "response:  Tanjung Benoa, Nusa Dua, Kuta, Uluwatu, dan Sanur\n",
      "prompt: Buat travel plan healing ke Jogja?\n",
      "response:  Yes\n",
      "prompt: Kalau lagi di Jakarta, bagusnya main ke mana aja?\n",
      "response:  Monas, Bundaran HI, Ancol\n",
      "prompt: Apa tempat wisata paling bagus di Medan?\n",
      "response:  Pasar Beringharjo\n",
      "prompt: Bagaimana caranya jadi mitra GoJek?\n",
      "response:  Menambahkan layanan.\n",
      "prompt: Akun GoPay saya terblokir?\n",
      "response:  No\n",
      "prompt: Gimana caranya top-up OVO?\n",
      "response:  Klik opsi OVO atau OVO Mobile pada menu\n",
      "prompt: Pesen cendol gimana?\n",
      "response:  enak\n",
      "prompt: Pesen gojek gimana?\n",
      "response:  Tidak terlalu bagus\n",
      "prompt: Belanja di tokped caranya gimana?\n",
      "response:  di tokped\n",
      "prompt: Cara sukses jualan di Shopee?\n",
      "response:  Sebelum menjual, pastikan Anda punya produk yang tepat yang dijual.\n",
      "prompt: Tips healing ampuh dong?\n",
      "response:  No\n",
      "prompt: Tips anti galau ala anak jaksel?\n",
      "response:  Jika ingin mengetahui lebih jelas bagaimana cara mengatasi galau, Anda bisa membaca di:\n",
      "prompt: Pesen grab gimana?\n",
      "response:  Sama seperti biasa\n",
      "prompt: Pesen taksi gimana?\n",
      "response:  Harganya mahal\n",
      "prompt: Tips sukses jualan di Tiktok?\n",
      "response:  Anda harus kreatif dan menguasai topik yang Anda jual\n",
      "prompt: Tips sukses dalam semalam?\n",
      "response:  tidak ada tips sukses untuk semalam\n",
      "prompt: Tips sukses cpns?\n",
      "response:  ya\n",
      "prompt: Tips sukses sistem kebut semalam?\n",
      "response:  Menghitung mundur ke angka tertentu hingga mencapai 1.\n",
      "prompt: Mau jalan-jalan di Pluit, kemana ya?\n",
      "response:  Pantai Ancol\n",
      "prompt: Mau jalan-jalan di Jaksel, kemana ya?\n",
      "response:  Katedral\n",
      "prompt: Mau jalan-jalan di PIM, kemana ya?\n",
      "response:  aku ke pim di akhir pekan nanti.\n",
      "prompt: Mau jalan-jalan di GI, kemana ya?\n",
      "response:  Saya tidak tahu, kita lihat nanti yaaa\n",
      "prompt: Kalau mau kuliah, bagusnya kuliah kemana ya?\n",
      "response:  Unpad\n",
      "prompt: Kalau mau kuliah, apa cuma kuliah negeri aja yang bagus?\n",
      "response:  itu pilihanmu, ada juga sekolah swasta\n",
      "prompt: Kalau mau kuliah, apa cuma kuliah swasta aja yang bagus?\n",
      "response:  Bukannya pemerintah juga punya universitas?\n",
      "prompt: Siapa anaknya Jokowi?\n",
      "response:  Tidak ada\n",
      "prompt: Siapa anaknya Soekarno?\n",
      "response:  Putri Rukmini\n",
      "prompt: Siapa presiden Indonesia yang pertama?\n",
      "response:  Soekarno\n",
      "prompt: Siapa presiden Indonesia yang kedua?\n",
      "response:  Soeharto\n",
      "prompt: Apa artinya sebelum negara api menyerang?\n",
      "response:  (Before a nation is attacked) It means to be unprepared.\n",
      "prompt: Jual mobil perlu BPKB ngga?\n",
      "response:  Yg penting SIM saja\n",
      "prompt: Jual mobil tanpa BPKB?\n",
      "response:  Jika Anda tidak mempunyai BPKB mobil, Anda bisa menjualnya di internet.\n",
      "prompt: Mendingan gw mampir pegadaian ngga ya?\n",
      "response:  Ngga mas.. aku di kantor..\n",
      "prompt: Cicil rumah bisa via KPR?\n",
      "response:  bisa\n",
      "prompt: Gimana caranya KPR murah?\n",
      "response:  Cari di tempat yang harganya murah\n",
      "prompt: Tips sukses KPR?\n",
      "response:  Saya baru mengetahui tentang produk KPR Bank Permata\n",
      "prompt: Kredit bunga rendah?\n",
      "response:  Yep.\n",
      "prompt: Kredit motor dong?\n",
      "response:  Not yet.\n",
      "prompt: Gimana cara manfaatin KTP ganda?\n",
      "response:  Menangkan lotre\n",
      "prompt: Tips sukses jualan di Tokped?\n",
      "response:  Cari tahu tentang tips sukses jualan di Bukalapak\n",
      "prompt: Tips sukses jualan di Tokopedia?\n",
      "response:  Beli produk yang punya banyak pembeli dan rating 5\n",
      "prompt: Gimana cara beli ketoprak?\n",
      "response:  Datang aja ke tempat penjualnya.\n",
      "prompt: Gimana cara bikin ketoprak?\n",
      "response:  Cari di internet ketoprak\n",
      "prompt: Ketoprak yg enak yg kayak apa?\n",
      "response:  Ketoprak Sunda\n",
      "prompt: Gimana cara beli gado-gado?\n",
      "response:  Kamu harus ke pasar\n",
      "prompt: Gimana cara bikin gado-gado?\n",
      "response:  dengan menggunakan bahan dasar yang berbeda\n",
      "prompt: Gado-gado yg enak yg kayak apa?\n",
      "response:  Roti Goreng\n",
      "prompt: Makanan khas Indo apa ya yang enak?\n",
      "response:  Nasi goreng\n",
      "prompt: Minta saran oleh-oleh khas Indo dong?\n",
      "response:  Yes\n",
      "prompt: Makanan khas Jakarta apa ya yang enak?\n",
      "response:  Bakpia\n",
      "prompt: Minta saran oleh-oleh khas Jakarta dong?\n",
      "response:  Nasi goreng.\n",
      "prompt: Makanan khas Bandung apa ya yang enak?\n",
      "response:  Mienya enak.\n",
      "prompt: Minta saran oleh-oleh khas Bandung dong?\n",
      "response:  Rambut palsu\n",
      "prompt: Apa bedanya pecel lele sama lele?\n",
      "response:  keduanya adalah lele\n",
      "prompt: Apa bedanya pecel lele sama pecel?\n",
      "response:  kedua istilah tersebut merujuk pada hidangan yang terbuat dari kacang-kacangan yang digiling halus dengan bumbu-bumbu\n",
      "prompt: Apa bedanya ketoprak dan gado-gado?\n",
      "response:  tidak ada\n",
      "prompt: Apa bedanya ketoprak dan karedok?\n",
      "response:  Ketoprak lebih manis, dan karedok lebih kering\n",
      "prompt: Apa bedanya gado-gado dan karedok?\n",
      "response:  karedok itu ada di Bogor Jawa Barat\n",
      "prompt: Akun Grab saya terblokir?\n",
      "response:  Anda mungkin pernah mengalami akun yang diblokir atau dinonaktifkan.\n",
      "prompt: Kenapa Jakarta macet banget ya?\n",
      "response:  Karena banyak mobil\n",
      "prompt: Gimana caranya jadi presiden?\n",
      "response:  Kita harus pilih kandidat yang pas.\n",
      "prompt: Gimana caranya jadi gubernur?\n",
      "response:  Kamu harus menang pemilu\n",
      "prompt: Gimana caranya jadi ketua RT?\n",
      "response:  Cari kandidat yang bisa mewakili\n",
      "prompt: Kenapa ngga ada yang mau jadi ketua RT?\n",
      "response:  Saya pernah ketua RT\n",
      "prompt: Apa sih bedanya RT dan RW?\n",
      "response:  itu soal pemekaran wilayah dan masalah administratif\n",
      "prompt: Apaan itu kelurahan dan kecamatan?\n",
      "response:  kecamatan adalah daerah administratif, kelurahan adalah daerah administratif, tetapi kota, kabupaten, provinsi adalah daerah administratif,\n",
      "prompt: Minta review product Wardah dong?\n",
      "response:  Yes\n",
      "prompt: Bisakah Anda jelaskan ulasan pelanggan yang negatif dan positif dari pelanggan yang telah membeli dan menggunakan Wardah untuk waktu yang cukup lama?\n",
      "response:  Negative\n"
     ]
    }
   ],
   "source": [
    "for model_path in [\n",
    "#     'aisingapore/sealion7b-instruct-nc',\n",
    "#     'Ichsan2895/Merak-7B-v4',\n",
    "#     'SeaLLMs/SeaLLM-7B-Chat',\n",
    "#     'meta-llama/Llama-2-7b-chat-hf',\n",
    "#     'bigscience/bloom-7b1---MBZUAI/bactrian-x-bloom-7b1-lora',\n",
    "#     'bigscience/bloom-7b1---haonan-li/bactrian-id-bloom-7b1-lora',\n",
    "    'bigscience/bloomz-7b1',\n",
    "#     'meta-llama/Llama-2-13b-chat-hf',\n",
    "#     'bigscience/mt0-xxl',\n",
    "]:\n",
    "    if 'bactrian' in model_path:\n",
    "        model_name, adapter_name = model_path.split('---')\n",
    "\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name, truncation_side='left', padding_side='right', trust_remote_code=True)\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True)\n",
    "        model = PeftModel.from_pretrained(model, adapter_name, torch_dtype=torch.float16).cuda()\n",
    "        model = model.merge_and_unload()\n",
    "        model_name = adapter_name.split('/')[-1]\n",
    "    elif 'mt0' in model_path:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_path, token='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')\n",
    "        model = AutoModelForSeq2SeqLM.from_pretrained(model_path, torch_dtype=torch.float16, token='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')\n",
    "        model_name = model_path.split('/')[-1]\n",
    "    else:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_path, token='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', trust_remote_code=True)\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=torch.float16, token='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', trust_remote_code=True).cuda()\n",
    "        model_name = model_path.split('/')[-1]\n",
    "\n",
    "    print(f'===== {model_name} =====')\n",
    "    responses = []\n",
    "    for prompt in prompts:\n",
    "        if 'sealion' in model_path:\n",
    "            prompt_template = \"### USER:\\n{human_prompt}\\n\\n### RESPONSE:\\n\"\n",
    "            formatted_prompt = prompt_template.format(human_prompt=prompt)\n",
    "        elif 'bactrian' in model_name or 'bloomz' in model_name:\n",
    "            prompt_template = \"USER: {human_prompt}\\nRESPONSE:\"\n",
    "            formatted_prompt = prompt_template.format(human_prompt=prompt)\n",
    "        else:\n",
    "            chats = [\n",
    "               {\"role\": \"user\", \"content\": prompt},\n",
    "               {\"role\": \"assistant\", \"content\": \"\"},\n",
    "            ]\n",
    "            formatted_prompt = tokenizer.apply_chat_template(chats, tokenize=False)\n",
    "        input_ids = tokenizer(formatted_prompt, return_tensors='pt', add_special_tokens=False)['input_ids'].cuda()\n",
    "        responses.append(\n",
    "            tokenizer.decode(\n",
    "                model.generate(\n",
    "                    input_ids, eos_token_id=tokenizer.eos_token_id, top_p=0.9, top_k=50, min_length=0, max_length=768, do_sample=True\n",
    "                )[0,input_ids.shape[1]:], skip_special_tokens=True\n",
    "            )\n",
    "        )\n",
    "        print(f'prompt: {prompt}')\n",
    "        print(f'response: {responses[-1]}')\n",
    "    pd.DataFrame({'prompts': prompts, 'responses': responses}).to_csv(f'./gen_save/baseline_{model_name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73c38cc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== bigscience/mt0-xxl =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 6/6 [00:52<00:00,  8.70s/it]\n",
      "\n",
      "No chat template is defined for this tokenizer - using a default chat template that implements the ChatML format (without BOS/EOS tokens!). If the default is not appropriate for your model, please set `tokenizer.chat_template` to an appropriate template. See https://huggingface.co/docs/transformers/main/chat_templating for more information.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Loaded mt0-xxl =====\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "\"addmm_impl_cpu_\" not implemented for 'Half'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m tokenizer(formatted_prompt, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m, add_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmt0\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m model_path:\n\u001b[1;32m     37\u001b[0m     responses\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m     38\u001b[0m         tokenizer\u001b[38;5;241m.\u001b[39mdecode(\n\u001b[0;32m---> 39\u001b[0m             \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m                \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m768\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     41\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m,:], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     42\u001b[0m         )\n\u001b[1;32m     43\u001b[0m     )\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     45\u001b[0m     responses\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m     46\u001b[0m         tokenizer\u001b[38;5;241m.\u001b[39mdecode(\n\u001b[1;32m     47\u001b[0m             model\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     50\u001b[0m         )\n\u001b[1;32m     51\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/generation/utils.py:1593\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1585\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m   1586\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA decoder-only architecture is being used, but right-padding was detected! For correct \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1587\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration results, please set `padding_side=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m` when initializing the tokenizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1588\u001b[0m         )\n\u001b[1;32m   1590\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m model_kwargs:\n\u001b[1;32m   1591\u001b[0m     \u001b[38;5;66;03m# if model is encoder decoder encoder_outputs are created\u001b[39;00m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;66;03m# and added to `model_kwargs`\u001b[39;00m\n\u001b[0;32m-> 1593\u001b[0m     model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_encoder_decoder_kwargs_for_generation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1594\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_input_name\u001b[49m\n\u001b[1;32m   1595\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;66;03m# 5. Prepare `input_ids` which will be used for auto-regressive generation\u001b[39;00m\n\u001b[1;32m   1598\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/generation/utils.py:742\u001b[0m, in \u001b[0;36mGenerationMixin._prepare_encoder_decoder_kwargs_for_generation\u001b[0;34m(self, inputs_tensor, model_kwargs, model_input_name)\u001b[0m\n\u001b[1;32m    740\u001b[0m encoder_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    741\u001b[0m encoder_kwargs[model_input_name] \u001b[38;5;241m=\u001b[39m inputs_tensor\n\u001b[0;32m--> 742\u001b[0m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m]: ModelOutput \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mencoder_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    744\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_kwargs\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/models/mt5/modeling_mt5.py:1083\u001b[0m, in \u001b[0;36mMT5Stack.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1068\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1069\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39mforward,\n\u001b[1;32m   1070\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1080\u001b[0m         output_attentions,\n\u001b[1;32m   1081\u001b[0m     )\n\u001b[1;32m   1082\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1083\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1084\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1085\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1086\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1087\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1088\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1089\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1090\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1091\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1092\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;66;03m# layer_outputs is a tuple with:\u001b[39;00m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/models/mt5/modeling_mt5.py:558\u001b[0m, in \u001b[0;36mMT5Block.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    556\u001b[0m     self_attn_past_key_value, cross_attn_past_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 558\u001b[0m self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m hidden_states, present_key_value_state \u001b[38;5;241m=\u001b[39m self_attention_outputs[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    568\u001b[0m attention_outputs \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m2\u001b[39m:]  \u001b[38;5;66;03m# Keep self-attention outputs and relative position weights\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/models/mt5/modeling_mt5.py:463\u001b[0m, in \u001b[0;36mMT5LayerSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    454\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    460\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    461\u001b[0m ):\n\u001b[1;32m    462\u001b[0m     normed_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm(hidden_states)\n\u001b[0;32m--> 463\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSelfAttention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnormed_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    472\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(attention_output[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    473\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (hidden_states,) \u001b[38;5;241m+\u001b[39m attention_output[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/models/mt5/modeling_mt5.py:381\u001b[0m, in \u001b[0;36mMT5Attention.forward\u001b[0;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n\u001b[1;32m    380\u001b[0m \u001b[38;5;66;03m# get query states\u001b[39;00m\n\u001b[0;32m--> 381\u001b[0m query_states \u001b[38;5;241m=\u001b[39m shape(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# (batch_size, n_heads, seq_length, dim_per_head)\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;66;03m# get key/value states\u001b[39;00m\n\u001b[1;32m    384\u001b[0m key_states \u001b[38;5;241m=\u001b[39m project(\n\u001b[1;32m    385\u001b[0m     hidden_states, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk, key_value_states, past_key_value[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    386\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \"addmm_impl_cpu_\" not implemented for 'Half'"
     ]
    }
   ],
   "source": [
    "for model_path in [\n",
    "#     'meta-llama/Llama-2-13b-chat-hf',\n",
    "    'bigscience/mt0-xxl',\n",
    "]:\n",
    "    print(f'===== {model_path} =====')\n",
    "    if 'bactrian' in model_path:\n",
    "        model_name, adapter_name = model_path.split('---')\n",
    "\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name, truncation_side='left', padding_side='right', trust_remote_code=True)\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True)\n",
    "        model = PeftModel.from_pretrained(model, adapter_name)\n",
    "        model.merge_and_unload()\n",
    "        model_name = adapter_name.split('/')[-1]\n",
    "    elif 'mt0' in model_path:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_path, token='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')\n",
    "        model = AutoModelForSeq2SeqLM.from_pretrained(model_path, torch_dtype=torch.float16, token='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')\n",
    "        model_name = model_path.split('/')[-1]\n",
    "    else:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_path, token='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', trust_remote_code=True)\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=torch.float16, token='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', trust_remote_code=True).cuda()\n",
    "        model_name = model_path.split('/')[-1]\n",
    "\n",
    "    print(f'===== Loaded {model_name} =====')\n",
    "    responses = []\n",
    "    for prompt in prompts:\n",
    "        if 'sealion' in model_path:\n",
    "            prompt_template = \"### USER:\\n{human_prompt}\\n\\n### RESPONSE:\\n\"\n",
    "            formatted_prompt = prompt_template.format(human_prompt=prompt)\n",
    "        else:\n",
    "            chats = [\n",
    "               {\"role\": \"user\", \"content\": prompt},\n",
    "               {\"role\": \"assistant\", \"content\": \"\"},\n",
    "            ]\n",
    "            formatted_prompt = tokenizer.apply_chat_template(chats, tokenize=False)\n",
    "        input_ids = tokenizer(formatted_prompt, return_tensors='pt', add_special_tokens=False)['input_ids']\n",
    "        if 'mt0' in model_path:\n",
    "            responses.append(\n",
    "                tokenizer.decode(\n",
    "                    model.generate(\n",
    "                        input_ids, eos_token_id=tokenizer.eos_token_id, top_p=0.9, top_k=50, min_length=0, max_length=768, do_sample=True\n",
    "                    )[0,:], skip_special_tokens=True\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            responses.append(\n",
    "                tokenizer.decode(\n",
    "                    model.generate(\n",
    "                        input_ids, eos_token_id=tokenizer.eos_token_id, top_p=0.9, top_k=50, min_length=0, max_length=768, do_sample=True\n",
    "                    )[0,input_ids.shape[1]:], skip_special_tokens=True\n",
    "                )\n",
    "            )\n",
    "        print(f'prompt: {prompt}')\n",
    "        print(f'response: {responses[-1]}')\n",
    "    pd.DataFrame({'prompts': prompts, 'responses': responses}).to_csv(f'./gen_save/baseline_{model_name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92e75c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
